{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION OF TOXIC COMMENTS ON INTERNET PLATFORMS - baseline models comparison</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id                                       comment_text  toxic  \\\n",
      "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0   \n",
      "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
      "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
      "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
      "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
      "\n",
      "   severe_toxic  obscene  threat  insult  identity_hate  \n",
      "0             0        0       0       0              0  \n",
      "1             0        0       0       0              0  \n",
      "2             0        0       0       0              0  \n",
      "3             0        0       0       0              0  \n",
      "4             0        0       0       0              0  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train_data = pd.read_csv(\"data/train.csv\")\n",
    "test_data = pd.read_csv(\"data/test.csv\")\n",
    "test_ground_truth = pd.read_csv(\"data/test_labels.csv\")\n",
    "print(train_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the toxic data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'category')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgcAAAGHCAYAAAAk+fF+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3XmYHGW59/Hvj4QlEFaBEZJAWAKyBBQii6JOACGAEM4RDnBQloPmvIoiGsWgIijwigqiuHDMKxhAJUREQEEhggMiskWEsB4iBBLCHgIJq4H7/aOeJlVDz0xPpmequ+f3ua6+puuppe+q7pm+59lKEYGZmZlZxQplB2BmZmaNxcmBmZmZFTg5MDMzswInB2ZmZlbg5MDMzMwKnByYmZlZgZMDsz6SNE3SaSW9tiT9XNLzkm4rIwYzaz1ODqzlSJor6SlJq+XKPiGpo8Sw+stuwIeBkRGxU9nB9DdJoyWFpKFlx1IvktolzS87DrM8JwfWqoYCnys7iN6SNKSXu2wMzI2Il/ojHquuVZKTVjkPqz8nB9aqvgt8UdJanVdU++9TUoekT6TnR0n6q6SzJS2S9LCk96XyeZKelnRkp8OuK2mmpMWSbpC0ce7Y70rrFkp6UNJ/5NZNk3SupKslvQSMrxLvhpKuTPvPkfTJVH4M8DNgV0lLJH2j2oWQ9ElJ96fY7pO0QyrfKp33Ikn3SjqgU1w/kfSHdOy/SnqnpO+nJowHJL0nt/1cSV+SdLeklySdJ6kt7b9Y0p8krZ3bfhdJN6fXvktSe6f34tT0moslXStp3bT6xvRzUYprV0mbp2v+gqRnJV3SxXWovO+TJC2Q9ISkybn1K0iaIumfkp6TNEPSOp32PUbSY8D1XbzGREn/kPRiOs6EVH507j14WNJ/p/LVgD8AG6bzWZLe7y5jSfsdIenRtO6kdP33TOtWTu/TgvT4vqSV07p2SfMlfVnSk8DPJd0jaf/csVdM1/Hd1c7RBomI8MOPlnoAc4E9gcuA01LZJ4CO9Hw0EMDQ3D4dwCfS86OApcDRwBDgNOAx4MfAysBewGJgeNp+Wlr+YFr/A+CmtG41YF461lBgB+BZYJvcvi8A7ydL1lepcj43AD8BVgHeDTwD7JGL9aZursXBwOPAewEBm5PVNqwIzAG+AqwE7J7OYctcXM8CO6bXvR54BDgid03+3Oma3wK0ASOAp4G/A+9J1+R64OS07QjgOWDfdM4fTsvr5d6LfwJbAMPS8hndvHcXA1+tXD9gty6uRWXfi9P7MjZdyz3T+uPTOYxMMf8UuLjTvhemfYdVOf5O6b38cIplBPCutG4/YLP0HnwIeBnYIa1rB+Z3OlZ3sWwNLCFrUloJOBP4V+48vpn2XR9YD7gZODX3WkuBb6fjDgNOAC7JvfZEYHbZv8d+lPsoPQA//Kj3g2XJwbbpj/V69D45eCi3bmzavi1X9hzw7vR8GjA9t2448AYwCjgE+Eun+H7Ksi/KacCF3ZzLqHSs1XNl3wKm5WLtLjm4BvhclfIPAE8CK+TKLgZOycX1/3LrPgvc3+maLOp0zQ/PLf8GOLfT/pen518GLqoS55G59+JruXWfBv7YzXt3ITCVrN9Fd5+Lyr7vypV9BzgvPb+flHSl5Q3IvnSH5vbdtJvj/xQ4u8bP6OWV94XqyUF3sXydlCikdasCr7MsOfgnsG9u/d5kTU+V13qdXBIKbEiWGK6Rli8FThjI31k/Gu/hZgVrWRFxD/B7YMpy7P5U7vkr6Xidy4bnluflXncJsJDsj+7GwM6p+nyRpEXA4cA7q+1bxYbAwohYnCt7lOy/0lqMIvuyqHbceRHxZjfH7Xy+3Z1/b7bfGDi40zXZjewLsOLJ3POXq7xW3glk/5HflppH/qubbaF4vR8luxaVuH6bi+l+ssSsrYt9O+vqWiNpH0m3pKahRWS1JutW27aGWDak+Hl7mSxZrdgwnVe1cwR4JiJeze2/APgr8FFlzXD7AL/sJjYbBNwZxVrdyWTV22flyiqd91YFXkzP81/Wy2NU5Ymk4cA6wAKyP+I3RMSHu9m3u1ujLgDWkbR6LkHYiKypoBbzyKqzqx13lKQVcgnCRsD/1njcvphHVnPwyeXY923XKiKeBCr9MHYD/iTpxoiY08UxRgEPpOcbkV2LSlz/FRF/7byDpNFdvX5O1Wud2vt/Q9Ykc0VE/EvS5WQJTVfH7C6WJ4Atc8vDgHfkNllAllzcm5bz59jV611AVrs2FPhbRNT6+bIW5ZoDa2npC+IS4Lhc2TNkX64fkzQk/adZ7Qu0N/aVtJuklYBTgVsjYh5ZzcUWkj6eOnqtKOm9kraqMf55ZG3G35K0iqTtgGOo/T+7n5F1zNxRmc2VdZa8lSxJOiHF1A7sD0zvzUkvp18A+0vaO13/VVJHuZE17PsM8CawaaVA0sG5fZ8n+/J7o5tjnCRpVUnbkPUFqXRg/B/g9HR9kLSepIm9OK/zgKMl7ZE6FI6Q9C6yfgErp9iXStqHrN9KxVPAOyStmSvrLpZLya7f+9Ln7RssSzQgax76WtpnXbJmiF/0EPvlZP1hPkfWTGODnJMDGwy+SdaJLO+TwJfIqmO3IfsC7otfkdVSLCTrxHc4QPpvfy/gULL/3p5kWWewWh1G1ua9APgtWX+FmbXsGBG/Bk5P8S0m+xJYJyJeBw4gq0J+lqzD4xER8UBXx6qXlPBMJOsM+QzZf8lfooa/R6kK/XTgr6nKfReyzpa3SloCXEnWlv9IN4e5gawz5nXAmRFxbSr/Qdr/WkmLyTr17dyL87qNLNk4m6yvyw3AxukzcBwwgyx5+c/0OpX9HiD7Qn84ndOG3cUSEfeS9eGYDjxB9r4+DbyWDnkacAdwNzCbrOas20m6IuIVstqNTcg68togp4juasnMzFpDahp4BFgxIpaWG039pGasRcCYHpKino7zdWCLiPhY3YKzpuWaAzOzJiNp/9Q0shrZUMbZZCNGlvd465A1V02tT4TW7JwcmJk1n4lkzUwLgDHAobGc1cDKJtWaB/whIm7saXsbHAakWUHS+cBHgKcjYttc+WeBz5BNynFVRJyQyk8ky2LfAI6LiGtS+QSytrghwM8i4oxUvglZ+9s6ZO1rH09tqmZmZtZLA1VzMA2YkC+QNJ4s+90uIrYhqxpD0tZknbe2Sfv8JPVoHkI2Q90+ZDOEHZa2hayD19kRMYasw88x/X5GZmZmLWpA5jmIiBtz44QrPkU2JepraZunU/lEstnmXgMekTSHbFpSgDkR8TCApOnAREn3k039+p9pmwuAU4Bze4pr3XXXjdGjO4dVrpdeeonVVuvcsd4683Wqna9VbXydaudrVZtGvE6zZs16NiLW62m7MidB2gL4gKTTgVeBL0bE7WQztN2S224+y2Ztm9epfGeyyT8W5Xof57d/G0mTgEkAbW1tnHnmmXU4lfpZsmQJw4d3Nxmcga9Tb/ha1cbXqXa+VrVpxOs0fvz4R3veqtzkYCiwNlAZpzxD0qYUJ/OoCKo3gUQ321cVEVNJPXLHjRsX7e3tvYu6n3V0dNBoMTUiX6fa+VrVxtepdr5WtWnm61RmcjAfuCz1sL1N0ptkc43PJzcVLdldySpTf1YrfxZYS9LQVHuQ397MzMx6qcyhjJeT9RVA0hZkU4w+SzYr2KHpnuSbkA3TuQ24HRgjaZM0ZeihwJUpufgzcFA67pHAFQN6JmZmZi1kQGoOJF1MdqvQdSXNJ5tm9nzgfEn3kN1C9Mj0RX+vpBnAfWRDHI+NiDfScT5DdmvXIcD5aRpRyG4BO13SacCdZHOcm5mZ2XIYqNEKh3Wxquo0nRFxOtn86Z3LrwaurlL+MMtGNJiZmVkfeIZEMzMzK3ByYGZmZgVODszMzKzAyYGZmZkVODkwMzOzAicHZmZmVlDmDIktY/SUq+p2rMljl3JUnY4394z96nIcMzMbXFxzYGZmZgVODszMzKzAyYGZmZkVODkwMzOzAicHZmZmVuDkwMzMzAqcHJiZmVmBkwMzMzMrcHJgZmZmBU4OzMzMrMDJgZmZmRU4OTAzM7MCJwdmZmZW4OTAzMzMCpwcmJmZWYGTAzMzMytwcmBmZmYFTg7MzMysYECSA0nnS3pa0j1V1n1RUkhaNy1L0jmS5ki6W9IOuW2PlPRQehyZK99R0uy0zzmSNBDnZWZm1ooGquZgGjChc6GkUcCHgcdyxfsAY9JjEnBu2nYd4GRgZ2An4GRJa6d9zk3bVvZ722uZmZlZbQYkOYiIG4GFVVadDZwARK5sInBhZG4B1pK0AbA3MDMiFkbE88BMYEJat0ZE/C0iArgQOLA/z8fMzKyVDS3rhSUdADweEXd1agUYAczLLc9PZd2Vz69S3tXrTiKrZaCtrY2Ojo7lP4lk8tilfT5GRduw+h2vHufWqJYsWdLS51dPvla18XWqna9VbZr5OpWSHEhaFfgqsFe11VXKYjnKq4qIqcBUgHHjxkV7e3tP4fboqClX9fkYFZPHLuWs2fV5W+Ye3l6X4zSijo4O6vHeDQa+VrXxdaqdr1Vtmvk6lTVaYTNgE+AuSXOBkcDfJb2T7D//UbltRwILeigfWaXczMzMlkMpyUFEzI6I9SNidESMJvuC3yEingSuBI5IoxZ2AV6IiCeAa4C9JK2dOiLuBVyT1i2WtEsapXAEcEUZ52VmZtYKBmoo48XA34AtJc2XdEw3m18NPAzMAf4f8GmAiFgInArcnh7fTGUAnwJ+lvb5J/CH/jgPMzOzwWBA+hxExGE9rB+dex7AsV1sdz5wfpXyO4Bt+xalmZmZgWdINDMzs06cHJiZmVmBkwMzMzMrcHJgZmZmBU4OzMzMrMDJgZmZmRU4OTAzM7MCJwdmZmZW4OTAzMzMCpwcmJmZWYGTAzMzMytwcmBmZmYFTg7MzMyswMmBmZmZFTg5MDMzswInB2ZmZlbg5MDMzMwKnByYmZlZgZMDMzMzK3ByYGZmZgVODszMzKzAyYGZmZkVODkwMzOzAicHZmZmVuDkwMzMzAoGJDmQdL6kpyXdkyv7rqQHJN0t6beS1sqtO1HSHEkPSto7Vz4hlc2RNCVXvomkWyU9JOkSSSsNxHmZmZm1ooGqOZgGTOhUNhPYNiK2A/4XOBFA0tbAocA2aZ+fSBoiaQjwY2AfYGvgsLQtwLeBsyNiDPA8cEz/no6ZmVnrGpDkICJuBBZ2Krs2IpamxVuAken5RGB6RLwWEY8Ac4Cd0mNORDwcEa8D04GJkgTsDlya9r8AOLBfT8jMzKyFDS07gOS/gEvS8xFkyULF/FQGMK9T+c7AO4BFuUQjv/3bSJoETAJoa2ujo6Ojr7EzeezSnjeqUduw+h2vHufWqJYsWdLS51dPvla18XWqna9VbZr5OpWeHEj6KrAU+GWlqMpmQfVajuhm+6oiYiowFWDcuHHR3t7em3CrOmrKVX0+RsXksUs5a3Z93pa5h7fX5TiNqKOjg3q8d4OBr1VtfJ1q52tVm2a+TqUmB5KOBD4C7BERlS/0+cCo3GYjgQXpebXyZ4G1JA1NtQf57c3MzKyXShvKKGkC8GXggIh4ObfqSuBQSStL2gQYA9wG3A6MSSMTViLrtHhlSir+DByU9j8SuGKgzsPMzKzVDNRQxouBvwFbSpov6RjgR8DqwExJ/5D0PwARcS8wA7gP+CNwbES8kWoFPgNcA9wPzEjbQpZkfEHSHLI+COcNxHmZmZm1ogFpVoiIw6oUd/kFHhGnA6dXKb8auLpK+cNkoxnMzMysjzxDopmZmRU4OTAzM7MCJwdmZmZW4OTAzMzMCpwcmJmZWYGTAzMzMytwcmBmZmYFTg7MzMyswMmBmZmZFTg5MDMzswInB2ZmZlZQU3Ig6TBJW6XnW0q6UdL1kt7Vv+GZmZnZQKu15uA0YGF6fibZLZRvBH7SH0GZmZlZeWq9K+N6EfGUpFWA3YCDgH8Bz/ZbZGZmZlaKWpODZyRtDowFbo+I1yStCqj/QjMzM7My1JocnArMAt4ADkllewB39UdQZmZmVp6akoOImCZpRnr+ciq+FTi0vwIzMzOzcvRmKOMw4KOSTkjLQ6m95sHMzMyaRK1DGT8EPAgcDpyUiscA5/ZTXGZmZlaSWmsOvg8cEhETgKWp7FZgp36JyszMzEpTa3IwOiKuS88j/XwdNyuYmZm1nFqTg/sk7d2pbE9gdp3jMTMzs5LV+p//ZOD3kq4Chkn6KbA/MLHfIjMzM7NS1FRzEBG3ANsB9wLnA48AO0XE7f0Ym5mZmZWgppoDSSsDz0TEd3JlK0paOSJe67fozMzMbMDV2udgJrBjp7IdgWtq2VnS+ZKelnRPrmwdSTMlPZR+rp3KJekcSXMk3S1ph9w+R6btH5J0ZK58R0mz0z7nSPK0zmZmZsup1uRgLNnQxbzbgO1r3H8aMKFT2RTguogYA1yXlgH2IZtDYQwwiTSXgqR1gJOBncmGUJ5cSSjSNpNy+3V+LTMzM6tRrcnBC0Bbp7I24KVado6IG1l2y+eKicAF6fkFwIG58gsjcwuwlqQNgL2BmRGxMCKeJ6vNmJDWrRERf4uIAC7MHcvMzMx6qdbRCr8BfiXpOOBhYDPge8CMPrx2W0Q8ARART0haP5WPAObltpufyrorn1+lvCpJk8hqGWhra6Ojo6MPp5CZPHZpzxvVqG1Y/Y5Xj3NrVEuWLGnp86snX6va+DrVzteqNs18nWpNDr4KnEXWlLAy8Crwc+Ar/RBTtf4CsRzlVUXEVGAqwLhx46K9vX05Qiw6aspVfT5GxeSxSzlrdn3mlpp7eHtdjtOIOjo6qMd7Nxj4WtXG16l2vla1aebrVOtQxlcj4lhgNeCdwPCI+ExEvNqH134qNQmQfj6dyucDo3LbjQQW9FA+skq5mZmZLYea78ooaU3gvWSdE8dL2l3S7n147SuByoiDI4ErcuVHpFELuwAvpOaHa4C9JK2dOiLuBVyT1i2WtEsapXBE7lhmZmbWS7XOc3AU8GNgCfByblUAm9aw/8VAO7CupPlkow7OAGZIOgZ4DDg4bX41sC8wJ73W0QARsVDSqUBl4qVvRkSlk+OnyEZEDAP+kB5mZma2HGpt3D4dOCgilutLNyIO62LVHlW2DeDYLo5zPtkMjZ3L7wC2XZ7YzMzMrKjWZoWhwLX9GYiZmZk1hlqTg28DX5NUcx8FMzMza061Nit8nmyUwgmSnsuviIiN6h6VmZmZlabW5OBj/RqFmZmZNYyakoOIuKG/AzEzM7PGUFMfAkkrSzpd0sOSXkhle0n6TP+GZ2ZmZgOt1g6GZ5MNFTycZVMT30s2v4CZmZm1kFr7HPwbsHlEvCTpTYCIeFxSlzc4MjMzs+ZUa83B63RKJCStBzxXfXMzMzNrVrUmB78GLpC0Cbx1o6QfAdP7KzAzMzMrR63JwVeAucBsYC3gIbI7H36jf8IyMzOzsvTY5yDNirgb8OWIOD41Jzyb7oFgZmZmLabHmoOIeBO4IiJeS8vPODEwMzNrXbU2K9woaZd+jcTMzMwaQq1DGR8F/iDpCmAey+Y6ICK+3h+BmZmZWTlqTQ6GAZen5yNz5W5eMDMzazG1dki8CPhrpd+BmZmZta5ed0g0MzOz1uYOiWZmZlbgDolmZmZW0NcOiWbWD0ZPuapux5o8dilH1eF4c8/Yrw7RmFkzqCk5iIij+zsQMzMzaww1JQeSNu1qXUQ8XL9wzMzMrGy1NivMIetnoFxZpd/BkLpGZGZmZqWqtVmhMKpB0juBk4G/9EdQZmZmVp5ahzIWRMSTwPHAt/oagKTPS7pX0j2SLpa0iqRNJN0q6SFJl0haKW27clqek9aPzh3nxFT+oKS9+xqXmZnZYLVcyUGyJbBqX15c0gjgOGBcRGxL1kRxKPBt4OyIGAM8DxyTdjkGeD4iNgfOTtshaeu03zbABOAnktzcYWZmthxqSg4k/UXSjbnHHcCtwPfqEMNQYJikoWTJxhPA7sClaf0FwIHp+cS0TFq/hySl8ukR8VpEPELWR2KnOsRmZmY26NTaIfFnnZZfAu6KiIf68uIR8bikM4HHgFeAa4FZwKKIWJo2mw+MSM9HkE3CREQslfQC8I5Ufkvu0Pl9CiRNAiYBtLW10dHR0ZdTALJx5PXSNqx+x6vHuTWqJUuWtPT5NeJnqpWvN7T+Z6qefK1q08zXqdYOiRf0vFXvSVqb7L/+TYBFwK+BfaqFUNmli3Vdlb+9MGIqMBVg3Lhx0d7e3rugq6jHBDMVk8cu5azZteZs3Zt7eHtdjtOIOjo6qMd716ga8TPVyp8naP3PVD35WtWmma9TrfMcXEbWB+AvubIPAJ+LiIP68Pp7Ao9ExDO513kfsJakoan2YCSwIG0/HxgFzE/NEGsCC3PlFfl9zMwGPc+6ab1Ra4fEDwE3dyr7GzC+j6//GLCLpFVT34E9gPuAPwOVpONI4Ir0/Mq0TFp/fUREKj80jWbYBBgD3NbH2MzMzAalWusaXwVWA17MlQ0H/tWXF4+IWyVdCvwdWArcSVblfxUwXdJpqey8tMt5wEWS5pDVGByajnOvpBlkicVS4NiIeKMvsZmZmQ1WtSYH1wA/lfTfEfGipDWAHwF/7GsAEXEy2YRKeQ9TZbRBRLwKHNzFcU4HTu9rPGZmZoNdrc0Kk4E1gIWSnib7r31NsomQzMzMrIXUOlrheWC/NG3yKGBemiXRzMzMWkytoxX2AuZGxP8CT6ayLYGNImJmP8ZnZmZmA6zWZoUfA4s7lS1O5WZmZtZCak0O1o+IJzqVPQG8s87xmJmZWclqTQ4elrR7p7J24JH6hmNmZmZlq3Uo4ynAZZLOA/4JbAYcnR5mZmbWQmqqOYiIK4C9yCZC2i/93DuVm5mZWQup+W4sEXEbnpLYzMys5fVYcyBptKRpkh6X9Fr6eYGkTQciQDMzMxtY3SYHkrYiu+/B+sBXgQPSz/WAO9J6MzMzayE9NSucAfw4Ik7qVD4t3RTpO8D+/RKZmZmZlaKn5OCDLLtFcmdn4aGMZmZmLaenPgdD6Pq2zP9K683MzKyF9JQc3E7XcxkcBdxR12jMzMysdD01K5wEXJNusnQp2ZTJGwAHkzU37N2/4ZmZmdlA67bmICJuJpv8aHvgOuCB9HN7YEJab2ZmZi2kx0mQIuJvwAclDQPWAZ6PiJf7PTIzMzMrRW9mSHwFeLwfYzEzM7MGUOtdGc3MzGyQcHJgZmZmBV0mB5K+m3u++8CEY2ZmZmXrruZgUu755f0diJmZmTWG7jok3iXpUuA+YGVJ36y2UUR8vV8iMzMzs1J0V3NwEPAPskmPBIyq8hjZ1wAkrSXpUkkPSLpf0q6S1pE0U9JD6efaaVtJOkfSHEl3S9ohd5wj0/YPSerqfhBmZmbWgy5rDiLiaeA0AElDI6KraZT76gfAHyPiIEkrAasCXwGui4gzJE0BpgBfBvYBxqTHzsC5wM6S1gFOBsYBAcySdGVEPN9PMZuZmbWsmkYrRMTRktaWdISkE9PPdfr64pLWILvz43npdV6PiEXAROCCtNkFwIHp+UTgwsjcAqwlaQOyaZxnRsTClBDMBCb0NT4zM7PBSBHR80bSrsBVZNMnPwpsBGwF7JdmUFy+F5feDUwl69ewPTAL+BzweESsldvu+YhYW9LvgTMi4qZUfh1ZjUI7sEpEVGo6TgJeiYgzq7zmJFJny7a2th2nT5++vOG/ZfbjL/T5GBVtw+CpV+pzrLEj1qzPgRrQkiVLGD58eNlh9JtG/Ey18ucJ/JnqDX+matOIn6nx48fPiohxPW1X6wyJ3wc+HRFvfZNKOgQ4B3jv8oX41uvvAHw2Im6V9AOyJoSuqEpZdFP+9sKIqWQJCePGjYv29vZeBVzNUVOu6vMxKiaPXcpZs2ueuLJbcw9vr8txGlFHRwf1eO8aVSN+plr58wT+TPWGP1O1aebPVK2TIG0BzOhUdimweR9ffz4wPyJuzR1zB+Cp1FxA+vl0bvtRuf1HAgu6KTczM7NeqjU5eAg4tFPZwcA/+/LiEfEkMC/dEhpgD7ImhivJbglN+nlFen4lcEQatbAL8EJEPAFcA+yV+kWsTXYnyWv6EpuZmdlgVWu90PHA7yUdR9bnYDTZiIGP1CGGzwK/TCMVHgaOJktaZkg6BniMLBEBuBrYF5gDvJy2JSIWSjoVuD1t982IWFiH2MzMzAadmpKDiLhZ0mbAfsCGwO+Aq+vxBRwR/yAbgtjZHlW2DeDYLo5zPnB+X+MxMzMb7Hpzy+bngV/0YyxmZmbWAHxXRjMzMytwcmBmZmYFTg7MzMysoObkQNLG/RmImZmZNYbe1BzcCZCGM5qZmVmL6na0gqRZZPc7uBMYkopPIZs22czMzFpQTzUHBwHXAhsDq0r6O7CypPGSWvuOGWZmZoNUT8nBChFxaURMARaT3TJZZLMa/kPSQ/0doJmZmQ2sniZB+pWkjcjud7AKsDbwakT8O4Ckdfo5PjMzMxtg3SYHEbGzpKHAWOAm4EfA6pLOBf6eHr6HgZmZWQvpcbRCRCyNiDuB1yPig8BLQAfZjZe+3b/hmZmZ2UCr+d4KwOfTz4iIS4BL+iEeMzMzK1nN8xxExLT0dNP+CcXMzMwaQa+nT053ZzQzM7MW5XsrmJmZWYGTAzMzMytwcmBmZmYFTg7MzMyswMmBmZmZFTg5MDMzswInB2ZmZlbg5MDMzMwKnByYmZlZgZMDMzMzK2iI5EDSEEl3Svp9Wt5E0q2SHpJ0iaSVUvnKaXlOWj86d4wTU/mDkvYu50zMzMyaX0MkB8DngPtzy98Gzo6IMcDzwDGp/Bjg+YjYHDg7bYekrYFDgW2ACcBPJA0ZoNjNzMxaSunJgaSRwH7Az9KygN2BS9MmFwAHpucT0zJp/R5p+4nA9Ih4LSIeAeYAOw3MGZiZmbUWRUS5AUiXAt8CVge+CBwF3JJqB5A0CvhDRGwr6R5gQkTMT+v+CewMnJL2+UUqPy/tc2mnl0PSJGASQFtb247Tp0/v8znMfvyFPh+jom0YPPVKfY41dsSa9TlQA1qyZAnDhw8vO4x+04ifqVb+PIE/U73hz1RtGvEzNX78+FkRMa6n7YYORDBdkfQR4OmImCVO2av7AAAXIElEQVSpvVJcZdPoYV13+xQLI6YCUwHGjRsX7e3t1TbrlaOmXNXnY1RMHruUs2bX522Ze3h7XY7TiDo6OqjHe9eoGvEz1cqfJ/Bnqjf8mapNM3+mSk0OgPcDB0jaF1gFWAP4PrCWpKERsRQYCSxI288HRgHzJQ0F1gQW5sor8vuYmZlZL5Ta5yAiToyIkRExmqxD4fURcTjwZ+CgtNmRwBXp+ZVpmbT++sjaRa4EDk2jGTYBxgC3DdBpmJmZtZSyaw668mVguqTTgDuB81L5ecBFkuaQ1RgcChAR90qaAdwHLAWOjYg3Bj5sMzOz5tcwyUFEdAAd6fnDVBltEBGvAgd3sf/pwOn9F6GZmdngUPpQRjMzM2ssTg7MzMyswMmBmZmZFTg5MDMzswInB2ZmZlbg5MDMzMwKnByYmZlZgZMDMzMzK3ByYGZmZgVODszMzKzAyYGZmZkVODkwMzOzAicHZmZmVuDkwMzMzAqcHJiZmVmBkwMzMzMrcHJgZmZmBU4OzMzMrMDJgZmZmRU4OTAzM7MCJwdmZmZW4OTAzMzMCpwcmJmZWYGTAzMzMytwcmBmZmYFpSYHkkZJ+rOk+yXdK+lzqXwdSTMlPZR+rp3KJekcSXMk3S1ph9yxjkzbPyTpyLLOyczMrNmVXXOwFJgcEVsBuwDHStoamAJcFxFjgOvSMsA+wJj0mAScC1kyAZwM7AzsBJxcSSjMzMysd0pNDiLiiYj4e3q+GLgfGAFMBC5Im10AHJieTwQujMwtwFqSNgD2BmZGxMKIeB6YCUwYwFMxMzNrGYqIsmMAQNJo4EZgW+CxiFgrt+75iFhb0u+BMyLiplR+HfBloB1YJSJOS+UnAa9ExJlVXmcSWa0DbW1tO06fPr3Psc9+/IU+H6OibRg89Up9jjV2xJr1OVADWrJkCcOHDy87jH7TiJ+pVv48gT9TveHPVG0a8TM1fvz4WRExrqfthg5EMD2RNBz4DXB8RLwoqctNq5RFN+VvL4yYCkwFGDduXLS3t/c63s6OmnJVn49RMXnsUs6aXZ+3Ze7h7XU5TiPq6OigHu9do2rEz1Qrf57An6ne8GeqNs38mSq7zwGSViRLDH4ZEZel4qdScwHp59OpfD4wKrf7SGBBN+VmZmbWS2WPVhBwHnB/RHwvt+pKoDLi4Ejgilz5EWnUwi7ACxHxBHANsJektVNHxL1SmZmZmfVS2c0K7wc+DsyW9I9U9hXgDGCGpGOAx4CD07qrgX2BOcDLwNEAEbFQ0qnA7Wm7b0bEwoE5BTMzs9ZSanKQOhZ21cFgjyrbB3BsF8c6Hzi/ftGZmZkNTqX3OTAzM7PGUnazgg0yo+vUY3ry2KV1630994z96nIcM7NW4ZoDMzMzK3ByYGZmZgVuVjAzM0vq1fQJ9Wv+LKPp0zUHZmZmVuDkwMzMzAqcHJiZmVmBkwMzMzMrcHJgZmZmBU4OzMzMrMDJgZmZmRU4OTAzM7MCJwdmZmZW4OTAzMzMCpwcmJmZWYGTAzMzMytwcmBmZmYFTg7MzMyswMmBmZmZFQwtOwAzs74YPeWquhxn8tilHFWnY809Y7+6HMesLK45MDMzswInB2ZmZlbg5MDMzMwKnByYmZlZQUslB5ImSHpQ0hxJU8qOx8zMrBm1THIgaQjwY2AfYGvgMElblxuVmZlZ82mZ5ADYCZgTEQ9HxOvAdGBiyTGZmZk1HUVE2THUhaSDgAkR8Ym0/HFg54j4TKftJgGT0uKWwIMDGmjP1gWeLTuIJuDrVDtfq9r4OtXO16o2jXidNo6I9XraqJUmQVKVsrdlPhExFZja/+EsH0l3RMS4suNodL5OtfO1qo2vU+18rWrTzNeplZoV5gOjcssjgQUlxWJmZta0Wik5uB0YI2kTSSsBhwJXlhyTmZlZ02mZZoWIWCrpM8A1wBDg/Ii4t+SwlkfDNnk0GF+n2vla1cbXqXa+VrVp2uvUMh0SzczMrD5aqVnBzMzM6sDJgZmZmRU4OTAzM7MCJwdmNihJen8tZWaDkZODkkn6N0lr5pbXknRgmTE1KkmrSVoht7yCpFXLjKmRSVqt7Bga3A9rLDNA0sG1lBlIGiZpy7Lj6AsnB+U7OSJeqCxExCLg5BLjaWTXAflkYFXgTyXF0rAkvU/SfcD9aXl7ST8pOayGIWlXSZOB9SR9Ifc4hWwYtFV3Yo1lg5qk/YF/AH9My++W1HRz7rTMPAdNrFqC5velulUiYkllISKWuOagqrOBvUmTgEXEXZI+WG5IDWUlYDjZ79nqufIXgYNKiaiBSdoH2BcYIemc3Ko1gKXlRNXQTiG7EWAHQET8Q9Lo8sJZPv4SKt8dkr5HdrvpAD4LzCo3pIb1kqQdIuLvAJJ2BF4pOaaGFBHzpMLtRt4oK5ZGExE3ADdImhYRj5YdTxNYQPY36QCKf5sWA58vJaLGtjQiXuj0+9d0nByU77PAScAlZDePuhY4ttSIGtfxwK8lVe6ZsQFwSInxNKp5kt4HRJpK/DhSE4MVvCzpu8A2wCqVwojYvbyQGk9E3AXcJekXEeGagp7dI+k/gSGSxpD9/t1ccky95hkSralIWpHsVtsCHoiIf5UcUsORtC7wA2BPliWcn4uI50oNrMFIupYsKf8i8H+AI4FnIuLLpQbWYCTNpsodbisiYrsBDKfhpabOrwJ7paJrgFMj4rXyouo9JwclkfT9iDhe0u+ofmvpA0oIqyFJ2j0irpf079XWR8RlAx2TNT9JsyJiR0l3V77gJN0QER8qO7ZGImnj7ta7aaZI0sER8eueyhqdmxXKc1H6eWapUTSHDwHXA/tXWReAk4McSesBnwRGk/sdj4j/KiumBlWpdXpC0n5kbesjS4ynIfnLv9dOBDonAtXKGpprDkomaf2IeLpT2ZYR8WBZMVlzk3Qz8BeyzmNvdUSMiN+UFlQDkvQRsus0imx+gzWAb0RE0w07GwiSFrOslnMlYEXgpYhYo7yoGkduVMd/kDVXVawBbB0RO5US2HJyzUH5/iLppIiYAZDGXx8DbF1uWI1H0kXAZyrzQqTqzvMjYo9yI2s4q7rdvGcR8fv09AVgfJmxNIOIyA/7JE3W1lRfeP1sAXAHLTKqwzUHJZO0Adk9v18F2sh6lU/Oj+e3jKT/Jvsl+wIwAvgS2bX6XamBNRhJpwE3R8TVZcfSyCRtAZwLtEXEtpK2Aw6IiNNKDq1pSLolInYpO45GImnFVugo7eSgAUg6lqxN6k3gsIj4a8khNSxJuwF/Bp4F3hMRT5YcUsNJ1b+rAa+nh4Bw9W+RpBvIEsyfRsR7Utk9EbFtuZE1pk4dglcAxgEfiohdSwqpIaXhi98iq/3ND5HdtLSgloObFUomaSbwBLAtWWeo8yXdGBFfLDeyxiPp42RzQhwBbAdcLenoNA7bks7Vv9alVSPitk6T1Xgcf9fyHYKXAnOBieWE0tB+TjYF/tlkzVVHkyXoTcXJQfl+HBGXp+eL0uQ1nq+8uo8Cu6UOnBdL+i0wDXhPqVE1GGXfdocDm0TEqZJGARtExG0lh9ZonpW0GamTnaSDyBJ1qyIiji47hiYxLCKuk6Q00uMUSX+hye6Z42aFBiCpDXhvWryt8+gF65qklSLi9bLjaCSSziVroto9IraStDZwbUS8t4ddBxVJm5L193kf8DzwCHC4h+5VJ+k7wGlkU5b/EdgeOD4iflFqYA1G0l+BDwCXkg3Bfhw4IyKa6i6NvitjyST9B3AbcDDZEJhb038w1omkkZJ+K+kZSU9J+g2wftlxNaCdI+JYsk6uRMTzZEPPLEm3/h4XEXsC6wHviojdnBh0a6+IeBH4CDAf2IKsz4YVHU92x9jjgB2Bj5PNvtlU3KxQvq8C763UFqQJbP5ElnVa0c+BX5ElUgAfS2UfLi2ixvQvSUNYVl2+HllNgiUR8aakzwAzIuKlsuNpEiumn/sCF0fEwma/uVB/iIjb09MlZP0NmpKTg/Kt0KkZ4Tlco9OV9SLi57nlaZKOLy2axnUO8FtgfUmnk92G+GvlhtSQZkr6ItmENW8lCBGxsLyQGtrvJD1A1qzw6ZR0vlpyTA0nDZH9ErAxxRlKm+qGXu5zULLUjrc9cHEqOgS425PYvJ2kP5F1QKxcq8OAoz0J0ttJehewB1kv6esiwndl7ETSI1WKo9mGnA2k1H/lxYh4I91gaA0PJy6SdBfwP7x9htJZXe7UgJwclEzSt4Fbgd3I/pDfCOzi5ODtJG0E/AjYlazK/GbguIh4rNTAGoykXYB7I2JxWl6dbPrWW8uNzJpdGk01muJ/xBeWFlADqtzQq+w4+srJQckk/T0iduhU9tZd4mwZSe/vPEFUtbLBTtKdwA6RfrlT57s7On/OzF92vZGmL98M+AfL/iOOiDiuvKgah6R10tPjgKfJmvbeuk1zszVXuc9BSSR9Cvg0sKmku3OrVgf8ZVfdD4HOX3DVygY7RS7rT53v/LveSVdfdoCTg+rGkdVA+T/K6maRfX4qvTTzIzkCaKrmKv/BKM+vgD+QTbM5JVe+uNkyzP4maVeysejrSfpCbtUawJByompoD0s6juy+AZAloQ+XGE+j8pdd79wDvBNPFFVVRGxSy3aSPhwRM/s7nr5yclCSdGfBF8g61Vn3VgKGk31e81MDv0jWE9+K/g/ZiIWvkf3Hch0wqdSIGpO/7HpnXeA+SbdRrC4/oLyQmtK3gYZPDtznwJqGpI27m6RG0g8j4rMDGZM1H0m/I0uaVgfeTTYJmb/seiDpQ9XKI+KGgY6lmUm6s3Kjr0bmmgNrGjXMXvf+AQmkwXma2x6dSdYu/G3gwFx5pcyqcBJQN03xH7mTA7PWs1dEnCDp38imuT2Y7DbXTg5Y9iUnacXOX3iShpUTVeOSdFNE7JZuBZ7/YvOtwFuYkwOz1uNpbrvhkUK9ExG7pZ++FXh9zC07gFo4ObBW4m/AjKe57Z5HClm/kXQH6T4w6aZnBRHx7wMfVe+5Q6I1HUmrVbtZjqSjImJaCSE1HE9za1YOSZuT3XDpEKCSKFzbbENmnRxY00iz2f0MGB4RG0naHvjviPh0yaE1FEmrkFWb70bWRnwTcG5EuPbAbICkmUk/QjbfyJvA+cAPmqV2ynf/s2ZyNrA32Z0riYi7gA+WGlFjuhDYhmz2yB8BWwEXlRqR2SAiaTvgLOC7wG/I5mN5Ebi+zLh6w30OrKlExLxOneve6GrbQWzLiNg+t/zndKc4M+tnkmYBi4DzgCkRUZlD41ZJTTPc2smBNZN5qWkhJK1EdoMT34r47e6UtEtE3AIgaWfcC99soBwcEYXpyiVtEhGPNEtnRHCfA2siktYFfgDsSTYy4VrgcxHxXKmBNQhJs8n6GKwIbAk8lpY3Bu6LiG1LDM9sUOjiTrtNdxtn1xxYU5A0BPh4RBxediwN7CO552sDH0jPbySr5jSzfiLpXWR9fdaUlK8hWANYpZyolp87JFpTiIg3gIllx9HIIuLRNMX0gWQdENcF1kvPfb8As/61JVmCvhawf+6xA/DJEuNaLm5WsKYh6XRgTeAS4K15DiLi76UF1YDSrH+7VuaCkLQa8LeI2K7cyMxan6RdI+JvZcfRV25WsGbyvvTzm7myAHYvIZZGJoqjON7As0ea9StJJ0TEd4D/lHRY5/URcVwJYS03JwfWNCJifNkxNImfkw2b+m1aPpBsWJWZ9Z/KyKk7So2iTtysYE1DUhvwf4ENI2IfSVuTVZ/7i68TSTuQzZAo4MaIuLPkkMwGBUkHR8SveyprdE4OrGlI+gPZf8VfjYjtJQ0F7oyIsSWHZmYGdDmU8W1ljc7NCtZM1o2IGZJOBIiIpZI8Q6KZlU7SPmS3SR8h6ZzcqjWApeVEtfycHFgzeUnSO8g6ISJpF+CFckMyMwNgAVl/gwOAWbnyxcDnS4moD9ysYE1D0o7AOcC2wD1kY/gPioi7Sw3MzCyRtGJE/KvsOPrKyYE1ldTPYEuyjnYPtsIvoZm1jnRzpVPIpi0fSva3KiJi0zLj6i0nB9Y00p0FLwEuiYh/lh2PmVlnkh4ga0aYRW6+kWa7B4yTA2sakjYGDkmPN8kShRkR8VipgZmZJZJujYidy46jr5wcWFOSNAY4CTg8IoaUHY+ZGYCkM4AhwGXAa5XyZpvm3aMVrKlIGg38B1ntwRvACWXGY2bWSaXWYFyurOmmeXfNgTUNSbcCKwK/Jut38HDJIZmZtSQnB9Y0JL0rIh4oOw4zs660yjTvK5QdgFkvPC/pvDSNMpK2lnRM2UGZmeVMA64BNkzL/wscX1o0y8nJgTWTabTAL52ZtbR1I2IG2YgqImIpxVuoNwUnB9ZMWuKXzsxaWktM8+7RCtZMWuKXzsxa2heAK4HNJP2VNM17uSH1njskWtOQtAPwQ3xvBTNrYK0wzbtrDqyZbAbsA4wCPko2ntifYTMrnaR/72LVFpKIiMsGNKA+8h9WayYnRcSvJa0N7AmcBZzLsklHzMzKsn/6uT7wPuD6tDwe6CCbMbFpuEOiNZNK58P9gP+JiCuAlUqMx8wMgIg4OiKOJusTtXVEfDQiPgpsU3Joy8XJgTWTxyX9lGz65KslrYw/w2bWWEZHxBO55aeALcoKZnm5Q6I1DUmrAhOA2RHxkKQNgLERcW3JoZmZASDpR8AY4GKyWoRDgTkR8dlSA+slJwdmZmZ1lDonfiAt3hgRvy0znuXh5MDMzMwKPFrBzMysjyTdFBG7SVpMmqitsgqIiFijpNCWi2sOzMzMrMA9vc3MzKzAyYGZmZkVODkwMzOzAicHZtZnkuZK2rPsOMysPpwcmFnTSne/M7M6c3JgZgWSRkm6TNIzkp6T9CNJm0m6Pi0/K+mXktZK218EbAT8TtISSSek8l0k3SxpkaS7JLXnXmMTSTdKWizpT5J+LOkXufUHSLo37dshaavcurmSvizpbuAlSV+S9JtO5/BDSd/v3ytl1rqcHJjZWyQNAX4PPAqMBkYA08nGan8L2BDYiuy22acARMTHgceA/SNieER8R9II4CrgNGAd4IvAbyStl17qV8BtwDvScT6ei2ELsqlnjwfWA64mSzzyN9k6jOwGXGsBvwAm5JKVocAhwEX1uSpmg4+TAzPL24ksAfhSRLwUEa9GxE0RMSciZkbEaxHxDPA94EPdHOdjwNURcXVEvBkRM4E7gH0lbQS8F/h6RLweETcBV+b2PQS4Kr3ev4AzgWFkt8GtOCci5kXEK+kmNzcCB6d1E4BnI2JWn6+G2SDl5MDM8kYBj0bE0nyhpPUlTZf0uKQXyf5bX7eb42wMHJyaBRZJWgTsBmxAlnwsjIiXc9vPyz3fkKzmAoCIeDOtH9HF9gAXkCUkpJ+uNTDrAycHZpY3D9ioSke/b5FNCbtdmgb2Y2RNDRWdp1qdB1wUEWvlHqtFxBnAE8A66S6bFaNyzxeQJRcASFJa/3g3r3c5sJ2kbYGPAL+s4VzNrAtODsws7zayL+8zJK0maRVJ7wdWB5YAi1J/gi912u8pYNPc8i+A/SXtLWlIOk67pJER8ShZE8MpklaStCuwf27fGcB+kvaQtCIwGXgNuLmroCPiVeBSUl+GiHisD9fAbNBzcmBmb4mIN8i+qDcn62Q4n6wPwDeAHYAXyDoaXtZp128BX0tNCF+MiHnAROArwDNkNQlfYtnfnMOBXYHnyDotXkKWABARD5LVTPwQeDbFs39EvN5D+BcAY3GTglmf+cZLZlY6SZcAD0TEyX04xkbAA8A7I+LFugVnNgi55sDMBpyk96a5E1aQNIGsluHyPhxvBeALwHQnBmZ959nFzKwM7yRrmngHWdPFpyLizuU5kKTVyPo8PEo2jNHM+sjNCmZmZlbgZgUzMzMrcHJgZmZmBU4OzMzMrMDJgZmZmRU4OTAzM7OC/w99yoSr4exr/wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_toxic = train_data[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "toxic_count = train_toxic.sum().to_frame()\n",
    "toxic_count['category'] = list(toxic_count.index)\n",
    "toxic_count['number_of_comments'] = toxic_count[0]\n",
    "toxic_count = toxic_count.drop(columns=[0]).reset_index()\n",
    "toxic_count = toxic_count.drop(columns=['index'])\n",
    "\n",
    "toxic_count.plot(x='category', y='number_of_comments', kind='bar', legend=False, grid=True, figsize=(8, 5))\n",
    "plt.title(\"Number of comments per category\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('category', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the comment data for visualizaton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '# of categories')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "rowsums = train_data.iloc[:,2:].sum(axis=1)\n",
    "x=rowsums.value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x.index, x.values)\n",
    "plt.title(\"Multiple categories per comment\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('# of categories', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(159571,)\n",
      "(153164,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## For getting the predicted variable\n",
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "# train, test = train_test_split(train_data, random_state=1, test_size=0.33, shuffle=True)\n",
    "X_train = train_data.comment_text\n",
    "X_test = test_data.comment_text\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove negative test cases\n",
    "def get_classification_report(y_test, preds):\n",
    "    new_y_test = y_test[y_test['toxic'] != -1]\n",
    "    new_preds = preds[y_test['toxic'] != -1]\n",
    "#     new_pred_prob = predict[y_test['toxic'] != -1]\n",
    "    print(classification_report(new_y_test, new_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ground_truth = pd.read_csv(\"test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ground_truth[\"toxic\"] = test_ground_truth.apply(lambda row: 0 if row.toxic == -1 else row.toxic,axis = 1)\n",
    "test_ground_truth[\"severe_toxic\"] = test_ground_truth.apply(lambda row: 0 if row.severe_toxic == -1 else row.severe_toxic,axis = 1)\n",
    "test_ground_truth[\"obscene\"] = test_ground_truth.apply(lambda row: 0 if row.obscene == -1 else row.obscene,axis = 1)\n",
    "test_ground_truth[\"threat\"] = test_ground_truth.apply(lambda row: 0 if row.threat == -1 else row.threat,axis = 1)\n",
    "test_ground_truth[\"insult\"] = test_ground_truth.apply(lambda row: 0 if row.insult == -1 else row.insult,axis = 1)\n",
    "test_ground_truth[\"identity_hate\"] = test_ground_truth.apply(lambda row: 0 if row.identity_hate == -1 else row.identity_hate,axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "# test = pd.read_csv(\"test.csv\")\n",
    "# train, test = train_test_split(train_data, random_state=1, test_size=0.33, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\n",
    "y = train[list_classes].values\n",
    "list_sentences_train = train[\"comment_text\"]\n",
    "list_sentences_test = test[\"comment_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(list_sentences_train))\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(list_sentences_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(list_sentences_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = 200\n",
    "X_t = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "X_te = pad_sequences(list_tokenized_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(totalNumWords,bins = np.arange(0,410,10))#[0,50,100,150,200,250,300,350,400])#,450,500,550,600,650,700,750,800,850,900])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    embed_size = 128\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = LSTM(60, return_sequences=True,name='lstm_layer')(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 143613 samples, validate on 15958 samples\n",
      "Epoch 1/2\n",
      "143613/143613 [==============================] - 695s 5ms/step - loss: 0.0683 - acc: 0.9780 - val_loss: 0.0493 - val_acc: 0.9820\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.04932, saving model to weights_base_new.best.hdf5\n",
      "Epoch 2/2\n",
      "143613/143613 [==============================] - 703s 5ms/step - loss: 0.0461 - acc: 0.9829 - val_loss: 0.0484 - val_acc: 0.9823\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.04932 to 0.04840, saving model to weights_base_new.best.hdf5\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "file_path=\"weights_base_new.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "\n",
    "callbacks_list = [checkpoint, early] #early\n",
    "model.fit(X_t, y, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks_list)\n",
    "\n",
    "model.load_weights(file_path)\n",
    "\n",
    "y_test = model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 66s 433us/step\n"
     ]
    }
   ],
   "source": [
    "y_test = model.predict([X_te], batch_size=1024, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dm = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/pandas/core/ops.py:1649: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = method(y)\n"
     ]
    }
   ],
   "source": [
    "test_dm = test_ground_truth[test_ground_truth.toxic == \"sda\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dm = test_dm[label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dm[list_classes] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dm['toxic'] = test_dm.apply(lambda x: 1 if x[\"toxic\"]>= 0.5 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dm['severe_toxic'] = test_dm.apply(lambda x: 1 if x[\"severe_toxic\"]>= 0.5 else 0, axis=1)\n",
    "test_dm['obscene'] = test_dm.apply(lambda x: 1 if x[\"obscene\"]>= 0.5 else 0, axis=1)\n",
    "test_dm['threat'] = test_dm.apply(lambda x: 1 if x[\"threat\"]>= 0.5 else 0, axis=1)\n",
    "test_dm['insult'] = test_dm.apply(lambda x: 1 if x[\"insult\"]>= 0.5 else 0, axis=1)\n",
    "test_dm['identity_hate'] = test_dm.apply(lambda x: 1 if x[\"identity_hate\"]>= 0.5 else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = test_dm[list_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = test_ground_truth[list_classes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.79      0.69      6090\n",
      "           1       0.49      0.20      0.28       367\n",
      "           2       0.65      0.75      0.69      3691\n",
      "           3       0.00      0.00      0.00       211\n",
      "           4       0.65      0.61      0.63      3427\n",
      "           5       0.00      0.00      0.00       712\n",
      "\n",
      "   micro avg       0.63      0.67      0.65     14498\n",
      "   macro avg       0.40      0.39      0.38     14498\n",
      "weighted avg       0.59      0.67      0.62     14498\n",
      " samples avg       0.07      0.06      0.06     14498\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(get_classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_y_test = y_true[y_true['toxic'] != -1]\n",
    "new_preds = y_pred[y_true['toxic'] != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9326956141173528\n",
      "Test accuracy is 0.9942323923848823\n",
      "Test accuracy is 0.9621432367376286\n",
      "Test accuracy is 0.9967019913095126\n",
      "Test accuracy is 0.9619713026352809\n",
      "Test accuracy is 0.9888711744662227\n",
      "Mean Accuracy is 0.9727692852751465\n"
     ]
    }
   ],
   "source": [
    "accuracies = []\n",
    "for category in (label_cols):\n",
    "    accuracies.append(accuracy_score(\n",
    "            new_y_test[category], new_preds[category]))\n",
    "    print('Test accuracy is {}'.format(accuracy_score(\n",
    "            new_y_test[category], new_preds[category])))\n",
    "print(\"Mean Accuracy is {}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(106912,)\n",
      "(52659,)\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "categories = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "train, test = train_test_split(train_data, random_state=1, test_size=0.33, shuffle=True)\n",
    "X_train = train.comment_text\n",
    "X_test = test.comment_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train_data\n",
    "test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', \n",
    "              'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def get_classification_report(y_test, preds):\n",
    "    new_y_test = y_test[y_test['toxic'] != -1]\n",
    "    new_preds = preds[y_test['toxic'] != -1]\n",
    "#     new_pred_prob = predict[y_test['toxic'] != -1]\n",
    "    print(classification_report(new_y_test, new_preds))\n",
    "\n",
    "    \n",
    "def get_accuracy(y_test, preds):\n",
    "    new_y_test = y_test[y_test['toxic'] != -1]\n",
    "    new_preds = preds[y_test['toxic'] != -1]\n",
    "    accuracies = []\n",
    "    for i, category in enumerate(label_cols):\n",
    "        accuracies.append(accuracy_score(\n",
    "                new_y_test[category], new_preds[:,i]))\n",
    "        print('Test accuracy is {}'.format(accuracy_score(\n",
    "                new_y_test[category], new_preds[:,i])))\n",
    "    #     new_pred_prob = predict[y_test['toxic'] != -1]\n",
    "    print(\"Mean Accuracy is {}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "CPU times: user 4min 54s, sys: 4.76 s, total: 4min 59s\n",
      "Wall time: 4min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "preds_prob = np.zeros((len(test), len(label_cols)))\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "pipelines = dict()\n",
    "\n",
    "for i, category in enumerate(label_cols):\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer( \n",
    "                    min_df=10, max_df=0.9, \n",
    "                    strip_accents='unicode',\n",
    "                    stop_words = \"english\",\n",
    "                    ngram_range=(1, 2),\n",
    "                    use_idf=1, smooth_idf=1, sublinear_tf=1 \n",
    "                )),\n",
    "                ('clf', OneVsRestClassifier(LogisticRegression(\n",
    "                    solver='sag'), n_jobs=1)),\n",
    "            ])\n",
    "    LogReg_pipeline.fit(train.comment_text, train[category])\n",
    "    pipelines[category] = LogReg_pipeline\n",
    "    # compute the testing accuracy\n",
    "#     prediction = LogReg_pipeline.predict(X_test)\n",
    "    preds[:,i] = LogReg_pipeline.predict(test.comment_text)\n",
    "    preds_prob[:,i] = LogReg_pipeline.predict_proba(test.comment_text)[:,1]\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(\n",
    "#         test_ground_truth[category], preds[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_ground_truth[label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.69      0.67      6090\n",
      "           1       0.41      0.31      0.35       367\n",
      "           2       0.77      0.60      0.68      3691\n",
      "           3       0.55      0.21      0.30       211\n",
      "           4       0.74      0.50      0.59      3427\n",
      "           5       0.69      0.25      0.37       712\n",
      "\n",
      "   micro avg       0.70      0.58      0.63     14498\n",
      "   macro avg       0.64      0.42      0.49     14498\n",
      "weighted avg       0.70      0.58      0.63     14498\n",
      " samples avg       0.06      0.05      0.05     14498\n",
      "\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(get_classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9371033792866298\n",
      "Test accuracy is 0.9934977648566695\n",
      "Test accuracy is 0.9667698271280752\n",
      "Test accuracy is 0.9968270342930382\n",
      "Test accuracy is 0.9635499703022914\n",
      "Test accuracy is 0.9903873206414705\n",
      "Mean Accuracy is 0.9746892160846959\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(get_accuracy(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "CPU times: user 4min 41s, sys: 6.31 s, total: 4min 47s\n",
      "Wall time: 4min 45s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "preds_prob = np.zeros((len(test), len(label_cols)))\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "pipelines = dict()\n",
    "\n",
    "for i, category in enumerate(label_cols):\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer( \n",
    "                    min_df=10, max_df=0.9, \n",
    "                    strip_accents='unicode',\n",
    "                    stop_words = \"english\",\n",
    "                    ngram_range=(1, 2),\n",
    "                    use_idf=1, smooth_idf=1, sublinear_tf=1 \n",
    "                )),\n",
    "                ('nb',  OneVsRestClassifier(MultinomialNB(\n",
    "                    fit_prior=True, class_prior=None))),\n",
    "            ])\n",
    "    LogReg_pipeline.fit(train.comment_text, train[category])\n",
    "    pipelines[category] = LogReg_pipeline\n",
    "    # compute the testing accuracy\n",
    "#     prediction = LogReg_pipeline.predict(X_test)\n",
    "    preds[:,i] = LogReg_pipeline.predict(test.comment_text)\n",
    "    preds_prob[:,i] = LogReg_pipeline.predict_proba(test.comment_text)[:,1]\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(\n",
    "#         test_ground_truth[category], preds[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.47      0.59      6090\n",
      "           1       0.71      0.04      0.08       367\n",
      "           2       0.90      0.37      0.52      3691\n",
      "           3       0.00      0.00      0.00       211\n",
      "           4       0.81      0.27      0.41      3427\n",
      "           5       1.00      0.01      0.02       712\n",
      "\n",
      "   micro avg       0.81      0.36      0.50     14498\n",
      "   macro avg       0.70      0.19      0.27     14498\n",
      "weighted avg       0.82      0.36      0.48     14498\n",
      " samples avg       0.04      0.03      0.03     14498\n",
      "\n",
      "None\n",
      "Test accuracy is 0.9371346400325111\n",
      "Test accuracy is 0.99440432648723\n",
      "Test accuracy is 0.9611741536153052\n",
      "Test accuracy is 0.9967019913095126\n",
      "Test accuracy is 0.957766732314233\n",
      "Test accuracy is 0.9889805870768077\n",
      "Mean Accuracy is 0.9726937384725999\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(get_classification_report(y_test, preds))\n",
    "print(get_accuracy(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing severe_toxic\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing obscene\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing threat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing insult\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing identity_hate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 21s, sys: 6.15 s, total: 8min 27s\n",
      "Wall time: 8min 24s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "preds_prob = np.zeros((len(test), len(label_cols)))\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "pipelines = dict()\n",
    "\n",
    "for i, category in enumerate(label_cols):\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer( \n",
    "                    min_df=10, max_df=0.9, \n",
    "                    strip_accents='unicode',\n",
    "                    stop_words = \"english\",\n",
    "                    ngram_range=(1, 2),\n",
    "                    use_idf=1, smooth_idf=1, sublinear_tf=1 \n",
    "                )),\n",
    "                ('rf', OneVsRestClassifier(RandomForestClassifier())),\n",
    "            ])\n",
    "    LogReg_pipeline.fit(train.comment_text, train[category])\n",
    "    pipelines[category] = LogReg_pipeline\n",
    "    # compute the testing accuracy\n",
    "#     prediction = LogReg_pipeline.predict(X_test)\n",
    "    preds[:,i] = LogReg_pipeline.predict(test.comment_text)\n",
    "    preds_prob[:,i] = LogReg_pipeline.predict_proba(test.comment_text)[:,1]\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(\n",
    "#         test_ground_truth[category], preds[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.74      0.65      6090\n",
      "           1       0.17      0.07      0.10       367\n",
      "           2       0.60      0.68      0.64      3691\n",
      "           3       0.46      0.06      0.11       211\n",
      "           4       0.58      0.52      0.55      3427\n",
      "           5       0.55      0.11      0.18       712\n",
      "\n",
      "   micro avg       0.58      0.62      0.60     14498\n",
      "   macro avg       0.49      0.36      0.37     14498\n",
      "weighted avg       0.57      0.62      0.58     14498\n",
      " samples avg       0.07      0.06      0.06     14498\n",
      "\n",
      "None\n",
      "Test accuracy is 0.9241145393729094\n",
      "Test accuracy is 0.992794398074338\n",
      "Test accuracy is 0.9559379786801713\n",
      "Test accuracy is 0.9966707305636312\n",
      "Test accuracy is 0.9539685516896433\n",
      "Test accuracy is 0.9891056300603333\n",
      "Mean Accuracy is 0.9687653047401711\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(get_classification_report(y_test, preds))\n",
    "print(get_accuracy(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "CPU times: user 20min 28s, sys: 18.2 s, total: 20min 46s\n",
      "Wall time: 20min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "preds_prob = np.zeros((len(test), len(label_cols)))\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "pipelines = dict()\n",
    "\n",
    "for i, category in enumerate(label_cols):\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer( \n",
    "                    min_df=10, max_df=0.9, \n",
    "                    strip_accents='unicode',\n",
    "                    stop_words = \"english\",\n",
    "                    ngram_range=(1, 2),\n",
    "                    use_idf=1, smooth_idf=1, sublinear_tf=1 \n",
    "                )),\n",
    "                ('XGboost', OneVsRestClassifier(GradientBoostingClassifier())),\n",
    "            ])\n",
    "    LogReg_pipeline.fit(train.comment_text, train[category])\n",
    "    pipelines[category] = LogReg_pipeline\n",
    "    # compute the testing accuracy\n",
    "#     prediction = LogReg_pipeline.predict(X_test)\n",
    "    preds[:,i] = LogReg_pipeline.predict(test.comment_text)\n",
    "    preds_prob[:,i] = LogReg_pipeline.predict_proba(test.comment_text)[:,1]\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(\n",
    "#         test_ground_truth[category], preds[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.47      0.56      6090\n",
      "           1       0.32      0.23      0.27       367\n",
      "           2       0.70      0.55      0.62      3691\n",
      "           3       0.38      0.43      0.40       211\n",
      "           4       0.73      0.40      0.51      3427\n",
      "           5       0.50      0.28      0.36       712\n",
      "\n",
      "   micro avg       0.68      0.46      0.55     14498\n",
      "   macro avg       0.56      0.39      0.45     14498\n",
      "weighted avg       0.69      0.46      0.54     14498\n",
      " samples avg       0.05      0.04      0.04     14498\n",
      "\n",
      "None\n",
      "Test accuracy is 0.9307574478727062\n",
      "Test accuracy is 0.9927631373284567\n",
      "Test accuracy is 0.9605801994435588\n",
      "Test accuracy is 0.9957954296789522\n",
      "Test accuracy is 0.9596892681859389\n",
      "Test accuracy is 0.9888399137203414\n",
      "Mean Accuracy is 0.9714042327049924\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(get_classification_report(y_test, preds))\n",
    "print(get_accuracy(y_test, preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Processing toxic\n",
      "... Processing severe_toxic\n",
      "... Processing obscene\n",
      "... Processing threat\n",
      "... Processing insult\n",
      "... Processing identity_hate\n",
      "CPU times: user 4min 8s, sys: 5.46 s, total: 4min 14s\n",
      "Wall time: 5min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "preds_prob = np.zeros((len(test), len(label_cols)))\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "\n",
    "pipelines = dict()\n",
    "\n",
    "for i, category in enumerate(label_cols):\n",
    "    print('... Processing {}'.format(category))\n",
    "    # train the model using X_dtm & y\n",
    "    LogReg_pipeline = Pipeline([\n",
    "                ('tfidf', TfidfVectorizer( \n",
    "                    min_df=10, max_df=0.9, \n",
    "                    strip_accents='unicode',\n",
    "                    stop_words = \"english\",\n",
    "                    ngram_range=(1, 2),\n",
    "                    use_idf=1, smooth_idf=1, sublinear_tf=1 \n",
    "                )),\n",
    "                ('clf', OneVsRestClassifier(LinearSVC(), n_jobs=1)),\n",
    "            ])\n",
    "    LogReg_pipeline.fit(train.comment_text, train[category])\n",
    "    pipelines[category] = LogReg_pipeline\n",
    "    # compute the testing accuracy\n",
    "#     prediction = LogReg_pipeline.predict(X_test)\n",
    "    preds[:,i] = LogReg_pipeline.predict(test.comment_text)\n",
    "#     preds_prob[:,i] = LogReg_pipeline.predict_proba(test.comment_text)[:,1]\n",
    "#     print('Test accuracy is {}'.format(accuracy_score(\n",
    "#         test_ground_truth[category], preds[:,i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.78      0.66      6090\n",
      "           1       0.38      0.36      0.37       367\n",
      "           2       0.68      0.69      0.69      3691\n",
      "           3       0.47      0.32      0.38       211\n",
      "           4       0.67      0.58      0.62      3427\n",
      "           5       0.63      0.33      0.43       712\n",
      "\n",
      "   micro avg       0.62      0.67      0.64     14498\n",
      "   macro avg       0.57      0.51      0.53     14498\n",
      "weighted avg       0.62      0.67      0.64     14498\n",
      " samples avg       0.07      0.06      0.06     14498\n",
      "\n",
      "None\n",
      "Test accuracy is 0.9246772327987746\n",
      "Test accuracy is 0.9929819625496265\n",
      "Test accuracy is 0.9637375347775798\n",
      "Test accuracy is 0.9965613179530464\n",
      "Test accuracy is 0.9622526493482134\n",
      "Test accuracy is 0.9903404295226484\n",
      "Mean Accuracy is 0.9717585211583147\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/Zhenfeng/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1145: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(get_classification_report(y_test, preds))\n",
    "print(get_accuracy(y_test, preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
