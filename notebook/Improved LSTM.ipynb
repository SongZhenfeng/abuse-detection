{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading and Analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting the toxic data for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'category')"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_ground_truth = pd.read_csv(\"test_labels.csv\")\n",
    "\n",
    "train_toxic = train_data[['toxic','severe_toxic','obscene','threat','insult','identity_hate']]\n",
    "toxic_count = train_toxic.sum().to_frame()\n",
    "toxic_count['category'] = list(toxic_count.index)\n",
    "toxic_count['number_of_comments'] = toxic_count[0]\n",
    "toxic_count = toxic_count.drop(columns=[0]).reset_index()\n",
    "toxic_count = toxic_count.drop(columns=['index'])\n",
    "\n",
    "toxic_count.plot(x='category', y='number_of_comments', kind='bar', legend=False, grid=True, figsize=(8, 5))\n",
    "plt.title(\"Number of comments per category\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('category', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, '# of categories')"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "rowsums = train_data.iloc[:,2:].sum(axis=1)\n",
    "x=rowsums.value_counts()\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "ax = sns.barplot(x.index, x.values)\n",
    "plt.title(\"Multiple categories per comment\")\n",
    "plt.ylabel('# of Occurrences', fontsize=12)\n",
    "plt.xlabel('# of categories', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start of work\n",
    "\n",
    "- Stopwords\n",
    "- Stem\n",
    "- Translation\n",
    "- Spell correction\n",
    "- Punctuation. Twitter style character preprocessing Keeping \"!\", \"?\" (but adding spaces between them) and single quotes.\n",
    "- Spam\n",
    "\n",
    "Reference\n",
    "- [Best single model](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644)\n",
    "- [1st place (Alex's model)](https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52557)\n",
    "- [Detailed instructions](https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda)\n",
    "- [Sample code based on Alex's model](https://www.kaggle.com/larryfreeman/toxic-comments-code-for-alexander-s-9872-model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(comment):\n",
    "    \"\"\"\n",
    "    This function receives comments and returns clean word-list\n",
    "    \"\"\"\n",
    "    # Convert to string\n",
    "    comment=str(comment)\n",
    "    #Convert to lower case , so that Hi and hi are the same\n",
    "#     comment=comment.lower()\n",
    "    #remove \\n\n",
    "    comment=re.sub(\"\\\\n\",\" \",comment)\n",
    "    # remove leaky elements like ip,user\n",
    "    comment=re.sub(\"\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\\.\\d{1,3}\",\"\",comment)\n",
    "    #removing usernames\n",
    "    comment=re.sub(\"\\[\\[.*\\]\",\"\",comment)\n",
    "    # https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/52644\n",
    "    special_character_removal=re.compile(r'[^a-z\\?\\!\\.\\,\\' ]',re.IGNORECASE)\n",
    "    comment=special_character_removal.sub(\" \", comment)\n",
    "    \n",
    "    #Split the sentences into words\n",
    "    words=tokenizer.tokenize(comment)\n",
    "    \n",
    "    # (')aphostophe  replacement (ie)   you're --> you are  \n",
    "    # ( basic dictionary lookup : master dictionary present in a hidden block of code)\n",
    "    words=[appos[word] if word in appos else word for word in words]\n",
    "    words=[lem.lemmatize(word, \"v\") for word in words]\n",
    "#     words = [w for w in words if not w in eng_stopwords]\n",
    "    \n",
    "    clean_sent=\" \".join(words)\n",
    "    clean_sent=re.sub(\"\\'\", \"\", clean_sent)\n",
    "    # remove any non alphanum,digit character\n",
    "    #clean_sent=re.sub(\"\\W+\",\" \",clean_sent)\n",
    "    #clean_sent=re.sub(\"  \",\" \",clean_sent)\n",
    "    return(clean_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "# Tweet tokenizer does not split at apostophes which is what we want\n",
    "from nltk.tokenize import TweetTokenizer   \n",
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "from appos import appos\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load input data\n",
    "EN = pd.read_csv(\"train.csv\")\n",
    "FR = pd.read_csv(\"train_fr.csv\")\n",
    "ES = pd.read_csv(\"train_es.csv\")\n",
    "DE = pd.read_csv(\"train_de.csv\")\n",
    "\n",
    "\n",
    "\n",
    "train_data = pd.concat([EN, FR, ES, DE])\n",
    "\n",
    "test_data = pd.read_csv(\"test.csv\")\n",
    "test_ground_truth = pd.read_csv(\"test_labels.csv\")\n",
    "\n",
    "\n",
    "# Prepare settings\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Prepare input data\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', \n",
    "              'insult', 'identity_hate']\n",
    "train_data['none'] = 1-train_data[label_cols].max(axis=1)\n",
    "\n",
    "train_data['comment_text'].fillna(\"something\", inplace=True)\n",
    "test_data['comment_text'].fillna(\"something\", inplace=True)\n",
    "\n",
    "\n",
    "# Initiate\n",
    "lem = WordNetLemmatizer()\n",
    "tokenizer=TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train and test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## For getting the predicted variable\n",
    "label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "\n",
    "train = train_data\n",
    "test = test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 31s, sys: 2.29 s, total: 5min 33s\n",
      "Wall time: 5min 36s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This is time-consuming. Set the boolean check if necessary\n",
    "if 1==1:\n",
    "    corpus_train = [clean(text) for text in train['comment_text']]\n",
    "    corpus_test = [clean(text) for text in test['comment_text']]\n",
    "    \n",
    "    # Write clean corpus to local\n",
    "    with open('clean_unigram_comment_train_with_stopword.txt', 'w', encoding='utf-8') as f:\n",
    "        for comment in corpus_train:\n",
    "            f.write(comment + '\\n')\n",
    "\n",
    "    with open('clean_unigram_comment_test_with_stopword.txt', 'w', encoding='utf-8') as f:\n",
    "        for comment in corpus_test:\n",
    "            f.write(comment + '\\n')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read processed corpus from local\n",
    "with open('clean_unigram_comment_train_with_stopword.txt', 'r') as f:\n",
    "    corpus_train = f.readlines()\n",
    "    \n",
    "with open('clean_unigram_comment_test_with_stopword.txt', 'r') as f:\n",
    "    corpus_test = f.readlines()    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['count_unique_word']=train[\"comment_text\"].apply(lambda x: len(set(str(x).split())))\n",
    "train['count_word']=train[\"comment_text\"].apply(lambda x: len(str(x).split()))\n",
    "train['word_unique_percent']=train['count_unique_word']*100/train['count_word']\n",
    "spammers=train[train['word_unique_percent']<30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spammers.comment_text.to_csv('spammer.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove negative test cases\n",
    "def get_classification_report(y_test, preds):\n",
    "    new_y_test = y_test[y_test['toxic'] != -1]\n",
    "    new_preds = preds[y_test['toxic'] != -1]\n",
    "#     new_pred_prob = predict[y_test['toxic'] != -1]\n",
    "    print(classification_report(new_y_test, new_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_false_negative(df, labels, label, preds, preds_prob, write=False, n=20):\n",
    "    for i, category in enumerate(labels):\n",
    "        df[category+'_prob'] = preds_prob[:,i]\n",
    "        df[category+'_pred'] = preds[:,i]\n",
    "    df['len_comment'] = df['comment_text'].apply(lambda x: len(x.split(' ')))\n",
    "    \n",
    "    if write:\n",
    "        for i, category in enumerate(labels):\n",
    "            print(\"... working on {}\".format(category))\n",
    "            df[['comment_text', category, category+'_prob', category+'_pred', 'len_comment']].iloc[\\\n",
    "                np.argwhere(preds[:,i] == 0).flatten().tolist()][df[category]==1].to_csv(\n",
    "                category+'_false_negative.csv')\n",
    "\n",
    "    return df[['comment_text', label, label+'_prob', label+'_pred', 'len_comment']].iloc[\n",
    "        np.argwhere(preds[:,0] == 0).flatten().tolist()][df['toxic']==1][:n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WIP\n",
    "def top_feats(tfidf, log_mod, n):\n",
    "    top_n_index = np.argpartition(log_mod.coef_[0], -n)[-n:]\n",
    "    feature_array = np.array(tfidf.get_feature_names())\n",
    "    return zip(top_n_index, feature_array[top_n_index], log_mod.coef_[0][top_n_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "import sys, os, re, csv, codecs, numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input:\n",
    "# corpus_train\n",
    "# corpus_test\n",
    "# train\n",
    "# test\n",
    "\n",
    "max_features = 20000\n",
    "tokenizer = Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(corpus_train)\n",
    "list_tokenized_train = tokenizer.texts_to_sequences(corpus_train)\n",
    "list_tokenized_test = tokenizer.texts_to_sequences(corpus_test)\n",
    "\n",
    "maxlen = 200\n",
    "x_train = pad_sequences(list_tokenized_train, maxlen=maxlen)\n",
    "x_test = pad_sequences(list_tokenized_test, maxlen=maxlen)\n",
    "y_train = train[label_cols].values\n",
    "y_test = test_ground_truth[label_cols]\n",
    "\n",
    "totalNumWords = [len(one_comment) for one_comment in list_tokenized_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    embed_size = 128\n",
    "    x = Embedding(max_features, embed_size)(inp)\n",
    "    x = LSTM(60, return_sequences=True,name='lstm_layer')(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 172771 samples, validate on 19197 samples\n",
      "Epoch 1/2\n",
      "172771/172771 [==============================] - 855s 5ms/step - loss: 0.0964 - acc: 0.9656 - val_loss: 0.3953 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39527, saving model to weights_base.best.hdf5\n",
      "Epoch 2/2\n",
      "172771/172771 [==============================] - 856s 5ms/step - loss: 0.0680 - acc: 0.9734 - val_loss: 0.3222 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39527 to 0.32224, saving model to weights_base.best.hdf5\n",
      "CPU times: user 1h 22min 52s, sys: 26min 9s, total: 1h 49min 1s\n",
      "Wall time: 28min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = get_model()\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "\n",
    "file_path=\"weights_base.best.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(file_path, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "\n",
    "early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=20)\n",
    "\n",
    "callbacks_list = [checkpoint, early] #early\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks=callbacks_list)\n",
    "\n",
    "model.load_weights(file_path)\n",
    "\n",
    "# y_test = model.predict(X_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 67s 434us/step\n",
      "CPU times: user 2min 51s, sys: 1min 19s, total: 4min 10s\n",
      "Wall time: 1min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "preds_prob = model.predict([x_test], batch_size=1024, verbose=1)\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "for i, category in enumerate(label_cols):\n",
    "    preds[:,i] = [1 if x >= 0.5 else 0 for x in preds_prob[:,i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.88      0.65      6090\n",
      "           1       0.44      0.40      0.42       367\n",
      "           2       0.59      0.79      0.67      3691\n",
      "           3       0.00      0.00      0.00       211\n",
      "           4       0.63      0.66      0.64      3427\n",
      "           5       0.67      0.00      0.01       712\n",
      "\n",
      "   micro avg       0.55      0.74      0.63     14498\n",
      "   macro avg       0.47      0.45      0.40     14498\n",
      "weighted avg       0.56      0.74      0.61     14498\n",
      " samples avg       0.08      0.07      0.07     14498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Remove negative test cases\n",
    "get_classification_report(y_test, preds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... working on toxic\n",
      "... working on severe_toxic\n",
      "... working on obscene\n",
      "... working on threat\n",
      "... working on insult\n",
      "... working on identity_hate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>severe_toxic_prob</th>\n",
       "      <th>severe_toxic_pred</th>\n",
       "      <th>len_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Arabs be commit genocide in Iraq , but no prot...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000625</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>How dare you vandalize that page about the HMS...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>Eek , but shes cute in an earthy kind of way ....</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>So , on the tenth anniversary of , New York Ti...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>Karl Tearle be a mop haired twat\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.002196</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1124</th>\n",
       "      <td>Intolerance in India india be a Generator of l...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000954</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>Because the overall aim of the project be wort...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1758</th>\n",
       "      <td>And cybersex .   .\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001470</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1863</th>\n",
       "      <td>I remove the frogs penis caption . The real na...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2003</th>\n",
       "      <td>someone , please edit this line The Lebanon Op...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2767</th>\n",
       "      <td>about Roy Keanes dog masturbation\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2971</th>\n",
       "      <td>Tiptoey , your some kind of chump for Goeathea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000854</td>\n",
       "      <td>0.0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3336</th>\n",
       "      <td>Hi Giggy ! Puny  shonen post pile of new feedb...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3365</th>\n",
       "      <td>make those kickass userboxes\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>U wot ? U wot ? U wot ? U wot ? U wot ? U wot ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4666</th>\n",
       "      <td>Gob Lofa I see your point but the experience o...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4949</th>\n",
       "      <td>masturbation , can we conclude\\n</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>Selena Gomez the truth You all have hear about...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>You delete the Belmont Blog ? ? ? Are you for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5165</th>\n",
       "      <td>wikibreak message This user be take a Wikibrea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000805</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           comment_text  severe_toxic  \\\n",
       "21    Arabs be commit genocide in Iraq , but no prot...             0   \n",
       "76    How dare you vandalize that page about the HMS...             0   \n",
       "219   Eek , but shes cute in an earthy kind of way ....             0   \n",
       "333   So , on the tenth anniversary of , New York Ti...             0   \n",
       "664                  Karl Tearle be a mop haired twat\\n             0   \n",
       "1124  Intolerance in India india be a Generator of l...             0   \n",
       "1255  Because the overall aim of the project be wort...             0   \n",
       "1758                               And cybersex .   .\\n             0   \n",
       "1863  I remove the frogs penis caption . The real na...             0   \n",
       "2003  someone , please edit this line The Lebanon Op...             0   \n",
       "2767                about Roy Keanes dog masturbation\\n             0   \n",
       "2971  Tiptoey , your some kind of chump for Goeathea...             0   \n",
       "3336  Hi Giggy ! Puny  shonen post pile of new feedb...             0   \n",
       "3365                     make those kickass userboxes\\n             0   \n",
       "3915  U wot ? U wot ? U wot ? U wot ? U wot ? U wot ...             0   \n",
       "4666  Gob Lofa I see your point but the experience o...             0   \n",
       "4949                   masturbation , can we conclude\\n             0   \n",
       "4977  Selena Gomez the truth You all have hear about...             0   \n",
       "4985  You delete the Belmont Blog ? ? ? Are you for ...             0   \n",
       "5165  wikibreak message This user be take a Wikibrea...             0   \n",
       "\n",
       "      severe_toxic_prob  severe_toxic_pred  len_comment  \n",
       "21             0.000625                0.0           20  \n",
       "76             0.000642                0.0           17  \n",
       "219            0.000239                0.0           26  \n",
       "333            0.000376                0.0          262  \n",
       "664            0.002196                0.0            7  \n",
       "1124           0.000954                0.0           11  \n",
       "1255           0.000305                0.0           85  \n",
       "1758           0.001470                0.0            6  \n",
       "1863           0.000198                0.0           46  \n",
       "2003           0.000083                0.0           33  \n",
       "2767           0.000907                0.0            5  \n",
       "2971           0.000854                0.0           42  \n",
       "3336           0.000765                0.0           44  \n",
       "3365           0.000012                0.0            4  \n",
       "3915           0.003800                0.0           37  \n",
       "4666           0.000103                0.0           70  \n",
       "4949           0.000478                0.0            5  \n",
       "4977           0.000497                0.0           91  \n",
       "4985           0.000015                0.0           96  \n",
       "5165           0.000805                0.0           22  "
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[label_cols] = y_test\n",
    "sample_false_negative(test, label_cols, 'severe_toxic', preds, preds_prob, write=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improved LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "\n",
    "import gensim\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Dropout, Conv1D, Embedding, SpatialDropout1D, concatenate\n",
    "from keras.layers import GRU, LSTM,Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D\n",
    "from keras.layers import CuDNNLSTM, CuDNNGRU\n",
    "from keras.preprocessing import text, sequence\n",
    "\n",
    "from keras.callbacks import Callback\n",
    "from keras import optimizers\n",
    "from keras.layers import Lambda\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import os\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "import gc\n",
    "from keras import backend as K\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from unidecode import unidecode\n",
    "\n",
    "import time\n",
    "\n",
    "eng_stopwords = set(stopwords.words(\"english\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input:\n",
    "\n",
    "def add_features(df):\n",
    "    \n",
    "    df['comment_text'] = df['comment_text'].apply(lambda x:str(x))\n",
    "    df['total_length'] = df['comment_text'].apply(len)\n",
    "    df['capitals'] = df['comment_text'].apply(lambda comment: sum(1 for c in comment if c.isupper()))\n",
    "    df['caps_vs_length'] = df.apply(lambda row: float(row['capitals'])/float(row['total_length']+0.1),\n",
    "                                axis=1)\n",
    "    df['num_words'] = df.comment_text.str.count('\\S+')\n",
    "    df['num_unique_words'] = df['comment_text'].apply(lambda comment: len(set(w for w in comment.split())))\n",
    "    df['words_vs_unique'] = df['num_unique_words'] / df['num_words']  \n",
    "\n",
    "    return df\n",
    "\n",
    "train = train_data\n",
    "test = test_data\n",
    "\n",
    "train['comment_text'] = corpus_train\n",
    "test['comment_text'] = corpus_test\n",
    "\n",
    "train = add_features(train)\n",
    "test = add_features(test)\n",
    "\n",
    "features = train[['caps_vs_length', 'words_vs_unique']].fillna(0)\n",
    "test_features = test[['caps_vs_length', 'words_vs_unique']].fillna(0)\n",
    "\n",
    "ss = StandardScaler()\n",
    "ss.fit(np.vstack((features, test_features)))\n",
    "features = ss.transform(features)\n",
    "test_features = ss.transform(test_features)\n",
    "\n",
    "y_train = train[label_cols].values\n",
    "y_test = test_ground_truth[label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "316576\n"
     ]
    }
   ],
   "source": [
    "# For best score (Public: 9869, Private: 9865), change to max_features = 283759, maxlen = 900\n",
    "max_features = 20000\n",
    "maxlen = 100\n",
    "\n",
    "tokenizer = text.Tokenizer(num_words=max_features)\n",
    "tokenizer.fit_on_texts(list(corpus_train) + list(corpus_test))\n",
    "X_train_sequence = tokenizer.texts_to_sequences(corpus_train)\n",
    "X_test_sequence = tokenizer.texts_to_sequences(corpus_test)\n",
    "\n",
    "x_train = sequence.pad_sequences(X_train_sequence, maxlen=maxlen)\n",
    "x_test = sequence.pad_sequences(X_test_sequence, maxlen=maxlen)\n",
    "print(len(tokenizer.word_index))\n",
    "\n",
    "y_train = train[label_cols].values\n",
    "y_test = test_ground_truth[label_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11 µs, sys: 18 µs, total: 29 µs\n",
      "Wall time: 33.9 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Load the FastText Web Crawl vectors\n",
    "EMBEDDING_FILE_FASTTEXT=\"/Users/Zhenfeng/Downloads/crawl-300d-2M.vec\"\n",
    "EMBEDDING_FILE_TWITTER=\"/Users/Zhenfeng/Downloads/glove/glove.twitter.27B.200d.txt\"\n",
    "def get_coefs(word, *arr): \n",
    "    return word, np.asarray(arr, dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index_ft = dict(get_coefs(*o.rstrip().rsplit(' ')) for o in open(EMBEDDING_FILE_FASTTEXT,encoding='utf-8'))\n",
    "embeddings_index_tw = dict(get_coefs(*o.strip().split()) for o in open(EMBEDDING_FILE_TWITTER,encoding='utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 2s, sys: 17.2 s, total: 8min 19s\n",
      "Wall time: 8min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "spell_model = gensim.models.KeyedVectors.load_word2vec_format(EMBEDDING_FILE_FASTTEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = spell_model.index2word\n",
    "\n",
    "w_rank = {}\n",
    "for i,word in enumerate(words):\n",
    "    w_rank[word] = i\n",
    "\n",
    "WORDS = w_rank\n",
    "\n",
    "# Use fast text as vocabulary\n",
    "def words(text): return re.findall(r'\\w+', text.lower())\n",
    "\n",
    "def P(word): \n",
    "    \"Probability of `word`.\"\n",
    "    # use inverse of rank as proxy\n",
    "    # returns 0 if the word isn't in the dictionary\n",
    "    return - WORDS.get(word, 0)\n",
    "\n",
    "def correction(word): \n",
    "    \"Most probable spelling correction for word.\"\n",
    "    return max(candidates(word), key=P)\n",
    "\n",
    "def candidates(word): \n",
    "    \"Generate possible spelling corrections for word.\"\n",
    "    return (known([word]) or known(edits1(word)) or known(edits2(word)) or [word])\n",
    "\n",
    "def known(words): \n",
    "    \"The subset of `words` that appear in the dictionary of WORDS.\"\n",
    "    return set(w for w in words if w in WORDS)\n",
    "\n",
    "def edits1(word):\n",
    "    \"All edits that are one edit away from `word`.\"\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    transposes = [L + R[1] + R[0] + R[2:] for L, R in splits if len(R)>1]\n",
    "    replaces   = [L + c + R[1:]           for L, R in splits if R for c in letters]\n",
    "    inserts    = [L + c + R               for L, R in splits for c in letters]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def edits2(word): \n",
    "    \"All edits that are two edits away from `word`.\"\n",
    "    return (e2 for e1 in edits1(word) for e2 in edits1(e1))\n",
    "\n",
    "def singlify(word):\n",
    "    return \"\".join([letter for i,letter in enumerate(word) if i == 0 or letter != word[i-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 6s, sys: 2.94 s, total: 2min 9s\n",
      "Wall time: 2min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_index = tokenizer.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "embedding_matrix = np.zeros((nb_words,501))\n",
    "\n",
    "something_tw = embeddings_index_tw.get(\"something\")\n",
    "something_ft = embeddings_index_ft.get(\"something\")\n",
    "\n",
    "something = np.zeros((501,))\n",
    "something[:300,] = something_ft\n",
    "something[300:500,] = something_tw\n",
    "something[500,] = 0\n",
    "\n",
    "def all_caps(word):\n",
    "    return len(word) > 1 and word.isupper()\n",
    "\n",
    "def embed_word(embedding_matrix,i,word):\n",
    "    embedding_vector_ft = embeddings_index_ft.get(word)\n",
    "    if embedding_vector_ft is not None: \n",
    "        if all_caps(word):\n",
    "            last_value = np.array([1])\n",
    "        else:\n",
    "            last_value = np.array([0])\n",
    "        embedding_matrix[i,:300] = embedding_vector_ft\n",
    "        embedding_matrix[i,500] = last_value\n",
    "        embedding_vector_tw = embeddings_index_tw.get(word)\n",
    "        if embedding_vector_tw is not None:\n",
    "            embedding_matrix[i,300:500] = embedding_vector_tw\n",
    "\n",
    "            \n",
    "# Fasttext vector is used by itself if there is no glove vector but not the other way around.\n",
    "for word, i in word_index.items():\n",
    "    \n",
    "    if i >= max_features: continue\n",
    "        \n",
    "    if embeddings_index_ft.get(word) is not None:\n",
    "        embed_word(embedding_matrix,i,word)\n",
    "    else:\n",
    "        # change to > 20 for better score. Previously 0\n",
    "        if len(word) > 20:\n",
    "            embedding_matrix[i] = something\n",
    "        else:\n",
    "            word2 = correction(word)\n",
    "            if embeddings_index_ft.get(word2) is not None:\n",
    "                embed_word(embedding_matrix,i,word2)\n",
    "            else:\n",
    "                word2 = correction(singlify(word))\n",
    "                if embeddings_index_ft.get(word2) is not None:\n",
    "                    embed_word(embedding_matrix,i,word2)\n",
    "                else:\n",
    "                    embedding_matrix[i] = something "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RocAucEvaluation(Callback):\n",
    "    def __init__(self, validation_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "\n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.max_score = 0\n",
    "        self.not_better_count = 0\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_pred = self.model.predict(self.X_val, verbose=1)\n",
    "            score = roc_auc_score(self.y_val, y_pred)\n",
    "            print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))\n",
    "            if (score > self.max_score):\n",
    "                print(\"*** New High Score (previous: %.6f) \\n\" % self.max_score)\n",
    "                model.save_weights(\"weights_alex.best.hdf5\")\n",
    "                self.max_score=score\n",
    "                self.not_better_count = 0\n",
    "            else:\n",
    "                self.not_better_count += 1\n",
    "                if self.not_better_count > 3:\n",
    "                    print(\"Epoch %05d: early stopping, high score = %.6f\" % (epoch,self.max_score))\n",
    "                    self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... working on toxic\n",
      "... working on severe_toxic\n",
      "... working on obscene\n",
      "... working on threat\n",
      "... working on insult\n",
      "... working on identity_hate\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>toxic_prob</th>\n",
       "      <th>toxic_pred</th>\n",
       "      <th>len_comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>116638</th>\n",
       "      <td>Bullshit! \\n\\nThe section used to be a neat li...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.070182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132808</th>\n",
       "      <td>\"\\n\\nUk55\\nI fess-up, you have caught me again...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.102789</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89694</th>\n",
       "      <td>You \\nDonny Osmond is an arsehole! Let me post...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50963</th>\n",
       "      <td>Vandalism \\n\\nStop vandalising pages. You are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25594</th>\n",
       "      <td>Elonka \\nSucks black cocks.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.119911</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30136</th>\n",
       "      <td>Please refrain from unmaking unconstructive ed...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.082884</td>\n",
       "      <td>0.0</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119339</th>\n",
       "      <td>\"\\n  \\n\\nYour request to be unblocked has been...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.092669</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87562</th>\n",
       "      <td>Stop with the garbage \\nI'll say irrelevant as...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.085786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105726</th>\n",
       "      <td>Thanks. Also thanks for freezing the article. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.115219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114979</th>\n",
       "      <td>The Cut-Away Diagram is Shit \\n\\nI hold two ba...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.083338</td>\n",
       "      <td>0.0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76598</th>\n",
       "      <td>DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FA...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.372704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151371</th>\n",
       "      <td>\"\\n\\nHey MF please don't leave Wiki I totally ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.082707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112140</th>\n",
       "      <td>Go screw yourself.68.79.88.224</td>\n",
       "      <td>1</td>\n",
       "      <td>0.112019</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10053</th>\n",
       "      <td>Materialscientist is a racist\\n\\nSeriously, fu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.073435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148725</th>\n",
       "      <td>republic of mosquito \\n\\nFAGGOT! FAGGOT! GET O...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.404125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110296</th>\n",
       "      <td>MAYBE YOU SHOULD READ OVER YOUR MESSAGES \\n\\nI...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.127606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101137</th>\n",
       "      <td>Holy shit, you are really doing this? You are ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.084772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8132</th>\n",
       "      <td>You suck. I was making the article and then yo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.107881</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139250</th>\n",
       "      <td>haha me grow up!? kid get a life and stop reve...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078452</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23496</th>\n",
       "      <td>Who is this stupid boy ? A kiwi, for sure.</td>\n",
       "      <td>1</td>\n",
       "      <td>0.109082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             comment_text  toxic  toxic_prob  \\\n",
       "116638  Bullshit! \\n\\nThe section used to be a neat li...      1    0.070182   \n",
       "132808  \"\\n\\nUk55\\nI fess-up, you have caught me again...      1    0.102789   \n",
       "89694   You \\nDonny Osmond is an arsehole! Let me post...      1    0.115277   \n",
       "50963   Vandalism \\n\\nStop vandalising pages. You are ...      1    0.119278   \n",
       "25594                         Elonka \\nSucks black cocks.      1    0.119911   \n",
       "30136   Please refrain from unmaking unconstructive ed...      1    0.082884   \n",
       "119339  \"\\n  \\n\\nYour request to be unblocked has been...      1    0.092669   \n",
       "87562   Stop with the garbage \\nI'll say irrelevant as...      1    0.085786   \n",
       "105726  Thanks. Also thanks for freezing the article. ...      1    0.115219   \n",
       "114979  The Cut-Away Diagram is Shit \\n\\nI hold two ba...      1    0.083338   \n",
       "76598   DIE FAG DIE FAG DIE FAG DIE FAG DIE FAG DIE FA...      1    0.372704   \n",
       "151371  \"\\n\\nHey MF please don't leave Wiki I totally ...      1    0.082707   \n",
       "112140                     Go screw yourself.68.79.88.224      1    0.112019   \n",
       "10053   Materialscientist is a racist\\n\\nSeriously, fu...      1    0.073435   \n",
       "148725  republic of mosquito \\n\\nFAGGOT! FAGGOT! GET O...      1    0.404125   \n",
       "110296  MAYBE YOU SHOULD READ OVER YOUR MESSAGES \\n\\nI...      1    0.127606   \n",
       "101137  Holy shit, you are really doing this? You are ...      1    0.084772   \n",
       "8132    You suck. I was making the article and then yo...      1    0.107881   \n",
       "139250  haha me grow up!? kid get a life and stop reve...      1    0.078452   \n",
       "23496          Who is this stupid boy ? A kiwi, for sure.      1    0.109082   \n",
       "\n",
       "        toxic_pred  len_comment  \n",
       "116638         0.0          108  \n",
       "132808         0.0           25  \n",
       "89694          0.0           15  \n",
       "50963          0.0            8  \n",
       "25594          0.0            4  \n",
       "30136          0.0           52  \n",
       "119339         0.0           21  \n",
       "87562          0.0           22  \n",
       "105726         0.0           14  \n",
       "114979         0.0           50  \n",
       "76598          0.0         1250  \n",
       "151371         0.0           34  \n",
       "112140         0.0            3  \n",
       "10053          0.0          142  \n",
       "148725         0.0            9  \n",
       "110296         0.0           51  \n",
       "101137         0.0           25  \n",
       "8132           0.0           18  \n",
       "139250         0.0           17  \n",
       "23496          0.0           10  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_false_negative(test, label_cols, 'toxic', preds, pred_prob, write=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(features,clipvalue=1.,num_filters=40,dropout=0.5,embed_size=501):\n",
    "    features_input = Input(shape=(features.shape[1],))\n",
    "    inp = Input(shape=(maxlen, ))\n",
    "    \n",
    "    # Layer 1: concatenated fasttext and glove twitter embeddings.\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "\n",
    "    x = LSTM(60, return_sequences=True,name='lstm_layer')(x)\n",
    "    x = GlobalMaxPool1D()(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(50, activation=\"relu\")(x)\n",
    "    x = Dropout(0.1)(x)\n",
    "    x = Dense(6, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=[inp,features_input], outputs=x)\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=['accuracy'])\n",
    "    return model    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "319142/319142 [==============================] - 783s 2ms/step - loss: 0.0550 - acc: 0.9803\n",
      "319142/319142 [==============================] - 161s 506us/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.984031 \n",
      "\n",
      "*** New High Score (previous: 0.000000) \n",
      "\n",
      "Epoch 2/5\n",
      "319142/319142 [==============================] - 810s 3ms/step - loss: 0.0464 - acc: 0.9825\n",
      "319142/319142 [==============================] - 167s 523us/step\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.985360 \n",
      "\n",
      "*** New High Score (previous: 0.984031) \n",
      "\n",
      "Epoch 3/5\n",
      "319142/319142 [==============================] - 807s 3ms/step - loss: 0.0435 - acc: 0.9834\n",
      "319142/319142 [==============================] - 167s 522us/step\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.986331 \n",
      "\n",
      "*** New High Score (previous: 0.985360) \n",
      "\n",
      "Epoch 4/5\n",
      "319142/319142 [==============================] - 780s 2ms/step - loss: 0.0408 - acc: 0.9841\n",
      "319142/319142 [==============================] - 170s 531us/step\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.987210 \n",
      "\n",
      "*** New High Score (previous: 0.986331) \n",
      "\n",
      "Epoch 5/5\n",
      "319142/319142 [==============================] - 795s 2ms/step - loss: 0.0387 - acc: 0.9849\n",
      "319142/319142 [==============================] - 164s 515us/step\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.987618 \n",
      "\n",
      "*** New High Score (previous: 0.987210) \n",
      "\n",
      "153164/153164 [==============================] - 79s 517us/step\n",
      "Epoch 1/5\n",
      "319142/319142 [==============================] - 792s 2ms/step - loss: 0.0545 - acc: 0.9805\n",
      "319142/319142 [==============================] - 163s 511us/step\n",
      "\n",
      " ROC-AUC - epoch: 1 - score: 0.983837 \n",
      "\n",
      "*** New High Score (previous: 0.000000) \n",
      "\n",
      "Epoch 2/5\n",
      "319142/319142 [==============================] - 792s 2ms/step - loss: 0.0456 - acc: 0.9828\n",
      "319142/319142 [==============================] - 167s 524us/step\n",
      "\n",
      " ROC-AUC - epoch: 2 - score: 0.985614 \n",
      "\n",
      "*** New High Score (previous: 0.983837) \n",
      "\n",
      "Epoch 3/5\n",
      "319142/319142 [==============================] - 781s 2ms/step - loss: 0.0426 - acc: 0.9837\n",
      "319142/319142 [==============================] - 164s 515us/step\n",
      "\n",
      " ROC-AUC - epoch: 3 - score: 0.986700 \n",
      "\n",
      "*** New High Score (previous: 0.985614) \n",
      "\n",
      "Epoch 4/5\n",
      "319142/319142 [==============================] - 788s 2ms/step - loss: 0.0400 - acc: 0.9846\n",
      "319142/319142 [==============================] - 165s 518us/step\n",
      "\n",
      " ROC-AUC - epoch: 4 - score: 0.986939 \n",
      "\n",
      "*** New High Score (previous: 0.986700) \n",
      "\n",
      "Epoch 5/5\n",
      "319142/319142 [==============================] - 792s 2ms/step - loss: 0.0380 - acc: 0.9851\n",
      "319142/319142 [==============================] - 170s 531us/step\n",
      "\n",
      " ROC-AUC - epoch: 5 - score: 0.987678 \n",
      "\n",
      "*** New High Score (previous: 0.986939) \n",
      "\n",
      "153164/153164 [==============================] - 80s 522us/step\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "model = get_model(features)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "\n",
    "epochs = 5\n",
    "gc.collect()\n",
    "K.clear_session()\n",
    "\n",
    "\n",
    "num_folds = 2 \n",
    "\n",
    "predict = np.zeros((test.shape[0],6))\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True, random_state=239)\n",
    "\n",
    "for train_index, test_index in kf.split(x_train):\n",
    "    \n",
    "    kfold_y_train,kfold_y_test = y_train[train_index], y_train[test_index]\n",
    "    kfold_X_train = x_train[train_index]\n",
    "    kfold_X_features = features[train_index]\n",
    "    kfold_X_valid = x_train[test_index]\n",
    "    kfold_X_valid_features = features[test_index] \n",
    "    \n",
    "    gc.collect()\n",
    "    K.clear_session()\n",
    "    \n",
    "    model = get_model(features)\n",
    "    \n",
    "    ra_val = RocAucEvaluation(validation_data=([kfold_X_valid,kfold_X_valid_features], kfold_y_test), interval = 1)\n",
    "    \n",
    "    model.fit([kfold_X_train,kfold_X_features], kfold_y_train, batch_size=batch_size, epochs=epochs, verbose=1,\n",
    "             callbacks = [ra_val])\n",
    "    gc.collect()\n",
    "    \n",
    "    predict += model.predict([x_test,test_features], batch_size=batch_size,verbose=1) / num_folds\n",
    "\n",
    "print(\"Done\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query to load model\n",
    "model = get_model(features)\n",
    "model.load_weights(\"weights_alex.best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153164/153164 [==============================] - 80s 524us/step\n"
     ]
    }
   ],
   "source": [
    "test[label_cols] = y_test\n",
    "pred_prob = model.predict([x_test,test_features], batch_size=32,verbose=1)\n",
    "preds = np.zeros((len(test), len(label_cols)))\n",
    "for i, category in enumerate(label_cols):\n",
    "    preds[:,i] = [1 if x >= 0.5 else 0 for x in pred_prob[:,i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.86      0.66      6090\n",
      "           1       0.35      0.53      0.42       367\n",
      "           2       0.60      0.79      0.68      3691\n",
      "           3       0.45      0.45      0.45       211\n",
      "           4       0.62      0.70      0.66      3427\n",
      "           5       0.67      0.51      0.58       712\n",
      "\n",
      "   micro avg       0.56      0.77      0.65     14498\n",
      "   macro avg       0.54      0.64      0.57     14498\n",
      "weighted avg       0.57      0.77      0.65     14498\n",
      " samples avg       0.07      0.07      0.07     14498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_classification_report(y_test, preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(y_test, preds):\n",
    "    new_y_test = y_test[y_test['toxic'] != -1]\n",
    "    new_preds = preds[y_test['toxic'] != -1]\n",
    "    accuracies = []\n",
    "    for i, category in enumerate(label_cols):\n",
    "        accuracies.append(accuracy_score(\n",
    "                new_y_test[category], new_preds[:,i]))\n",
    "        print('Test accuracy is {}'.format(accuracy_score(\n",
    "                new_y_test[category], new_preds[:,i])))\n",
    "    #     new_pred_prob = predict[y_test['toxic'] != -1]\n",
    "    print(\"Mean Accuracy is {}\".format(np.mean(accuracies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy is 0.9151270749320078\n",
      "Test accuracy is 0.9915127074932008\n",
      "Test accuracy is 0.9570633655319016\n",
      "Test accuracy is 0.9964050142236394\n",
      "Test accuracy is 0.9610647410047204\n",
      "Test accuracy is 0.9917471630873113\n",
      "Mean Accuracy is 0.9688200110454636\n"
     ]
    }
   ],
   "source": [
    "get_accuracy(y_test, preds)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
