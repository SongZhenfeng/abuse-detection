{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Reference https://github.com/PavelOstyakov/toxic/tree/master/tools\n",
    "from joblib import Parallel, delayed\n",
    "from textblob import TextBlob\n",
    "from textblob.translate import NotTranslated\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "NAN_WORD = \"_NAN_\"\n",
    "\n",
    "\n",
    "def translate(comment, language):\n",
    "    if hasattr(comment, \"decode\"):\n",
    "        comment = comment.decode(\"utf-8\")\n",
    "\n",
    "    text = TextBlob(comment)\n",
    "    try:\n",
    "        text = text.translate(to=language)\n",
    "        text = text.translate(to=\"en\")\n",
    "    except NotTranslated:\n",
    "        pass\n",
    "\n",
    "    return str(text)\n",
    "\n",
    "\n",
    "def main():\n",
    "    parser = argparse.ArgumentParser(\"Script for extending train dataset\")\n",
    "    parser.add_argument(\"train_file_path\")\n",
    "    parser.add_argument(\"--languages\", nargs=\"+\", default=[\"zh\", \"pt\",\"es\", \"de\", \"fr\"])\n",
    "    parser.add_argument(\"--thread-count\", type=int, default=300)\n",
    "    parser.add_argument(\"--result-path\", default=\"extended_data\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    train_data = pd.read_csv(args.train_file_path)\n",
    "    comments_list = train_data[\"comment_text\"].fillna(NAN_WORD).values\n",
    "\n",
    "    if not os.path.exists(args.result_path):\n",
    "        os.mkdir(args.result_path)\n",
    "\n",
    "    parallel = Parallel(args.thread_count, backend=\"threading\", verbose=5)\n",
    "    for language in args.languages:\n",
    "        print('Translate comments using \"{0}\" language'.format(language))\n",
    "        translated_data = parallel(delayed(translate)(comment, language) for comment in comments_list)\n",
    "        train_data[\"comment_text\"] = translated_data\n",
    "\n",
    "        result_path = os.path.join(args.result_path, \"train_\" + language + \".csv\")\n",
    "        train_data.to_csv(result_path, index=False)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
